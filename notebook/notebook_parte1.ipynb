{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em seguida iremos importar diversas bibliotecas que serão utilizadas:\n",
    "\n",
    "# Pacote para trabalhar com JSON\n",
    "import json\n",
    "\n",
    "# Pacote para realizar requisições HTTP\n",
    "import requests\n",
    "\n",
    "# Pacote para exploração e análise de dados\n",
    "import pandas as pd\n",
    "\n",
    "# Pacote com métodos numéricos e representações matriciais\n",
    "import numpy as np\n",
    "\n",
    "# Pacote para construção de modelo baseado na técnica Gradient Boosting\n",
    "import xgboost as xgb\n",
    "\n",
    "# Pacotes do scikit-learn para pré-processamento de dados\n",
    "# \"SimpleImputer\" é uma transformação para preencher valores faltantes em conjuntos de dados\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Pacotes do scikit-learn para treinamento de modelos e construção de pipelines\n",
    "# Método para separação de conjunto de dados em amostras de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Método para criação de modelos baseados em árvores de decisão\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pacotes do scikit-learn para avaliação de modelos\n",
    "# Métodos para validação cruzada do modelo criado\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_1 = pd.read_csv(\"../data_asset/dataset_desafio_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das colunas que serão features (entradas) da Pipeline\n",
    "features = [\n",
    "    \"MATRICULA\", \"NOME\", 'REPROVACOES_DE', 'REPROVACOES_EM', \"REPROVACOES_MF\", \"REPROVACOES_GO\",\n",
    "    \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\",\n",
    "    \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n",
    "]\n",
    "\n",
    "X = df_data_1[features]\n",
    "Y = df_data_1[\"PERFIL\"].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Trata os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Proporcionalidade de atividades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PrepareData(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, drop_colums, proporcional_in_columns, merge_comlumns_to_name):\n",
    "        self.drop_colums = drop_colums\n",
    "        self.proporcional_in_columns = proporcional_in_columns\n",
    "        self.merge_comlumns_to_name = merge_comlumns_to_name\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def proporcional_in_column(self, data):\n",
    "        d = data.copy()\n",
    "        for column in self.proporcional_in_columns:\n",
    "            median = data[column].median()\n",
    "\n",
    "            numpy_column = data[column]\n",
    "            numpy_colum = np.array(numpy_column)\n",
    "\n",
    "            for i in range(len(numpy_colum)):\n",
    "                numpy_colum[i] = numpy_colum[i] / median\n",
    "\n",
    "            d[column] = numpy_colum\n",
    "        return d\n",
    "    \n",
    "    def merge_two_comlumns(self, data):\n",
    "        d = data.copy()\n",
    "        new_column = list()\n",
    "        sum_median = data[self.merge_comlumns_to_name[0]].median() + data[self.merge_comlumns_to_name[1]].median()\n",
    "        \n",
    "        numpy_column1 = np.array(data[self.merge_comlumns_to_name[0]])\n",
    "        numpy_column2 = np.array(data[self.merge_comlumns_to_name[1]])\n",
    "        \n",
    "        for i in range(0, len(data[self.merge_comlumns_to_name[0]])):\n",
    "            v = (numpy_column1[i] + numpy_column2[i]) / sum_median\n",
    "            new_column.append(v)\n",
    "\n",
    "        d = d.drop([self.merge_comlumns_to_name[0],self.merge_comlumns_to_name[1]], axis=1)\n",
    "        d[self.merge_comlumns_to_name[2]] = new_column\n",
    "\n",
    "        return d\n",
    "\n",
    "    def transform(self,X):\n",
    "        data = self.proporcional_in_column(X)\n",
    "        data = self.merge_two_comlumns(data)\n",
    "        data = self.nan_values(data)\n",
    "        return data.drop(labels=self.drop_colums,axis='columns')\n",
    "    \n",
    "    def nan_values(self,X):\n",
    "        si = SimpleImputer(\n",
    "            missing_values=np.nan,  # os valores faltantes são do tipo ``np.nan`` (padrão Pandas)\n",
    "            strategy='constant',  # a estratégia escolhida é a alteração do valor faltante por uma constante\n",
    "            fill_value=0,  # a constante que será usada para preenchimento dos valores faltantes é um int64=0.\n",
    "            verbose=0,\n",
    "            copy=True\n",
    "        )\n",
    "        \n",
    "        si.fit(X=X)\n",
    "\n",
    "        # Reconstrução de um novo DataFrame Pandas com o conjunto imputado (df_data_3)\n",
    "        data = pd.DataFrame.from_records(\n",
    "            data=si.transform(\n",
    "                X=X\n",
    "            ),  # o resultado SimpleImputer.transform(<<pandas dataframe>>) é lista de listas\n",
    "            columns=X.columns  # as colunas originais devem ser conservadas nessa transformação\n",
    "        )\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['NOME',\"MATRICULA\",\"FALTAS\",\"INGLES\"]\n",
    "proporcional_in_columns = [\"NOTA_DE\",\"NOTA_GO\",\"NOTA_MF\",\"NOTA_EM\"]\n",
    "merge_comlumns_to_name = [\"H_AULA_PRES\",\"TAREFAS_ONLINE\",\"ATIVIDADES\"]\n",
    "features_to_model = [\n",
    "    'REPROVACOES_DE', 'REPROVACOES_EM', \"REPROVACOES_MF\", \"REPROVACOES_GO\",\n",
    "    \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\", \"ATIVIDADES\"\n",
    "]\n",
    "prepare_data = PrepareData(drop_columns,proporcional_in_columns,merge_comlumns_to_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Encodificação de Y e separação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class DenseModel(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self,input_s, num_classes, batch_size, epochs, activation, prepare_data):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.input_s = input_s\n",
    "        self.activation = activation\n",
    "        self.num_classes=num_classes\n",
    "        self.prepare_data=prepare_data\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, self.transform_label(Y), test_size=0.2, random_state=337)\n",
    "        self.model = self.create()\n",
    "        self.history = self.model.fit(X_train, Y_train,\n",
    "                            batch_size=self.epochs,\n",
    "                            epochs=self.batch_size,\n",
    "                            validation_data=(X_val, Y_val)\n",
    "                            )\n",
    "        return self\n",
    "\n",
    "    def create(self):\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(self.input_s,\n",
    "                        activation=self.activation,\n",
    "                        input_shape=(self.input_s,)))\n",
    "        \n",
    "        model.add(Dense(self.num_classes,\n",
    "                        activation=self.activation))\n",
    "        \n",
    "        model.add(Dense(self.num_classes,\n",
    "                        activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=\"adam\",\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy']\n",
    "                      )\n",
    "        return model\n",
    "\n",
    "    def predict(self,X):\n",
    "        data = self.prepare_data.transform(X.copy())\n",
    "        return self.reverse_predicitions_to_label(self.model.predict(data))\n",
    "\n",
    "    def evaluate(self,X_test,Y_test):\n",
    "        data = self.prepare_data.transform(X_test.copy())\n",
    "        return self.model.evaluate(data,self.transform_label(Y_test))\n",
    "\n",
    "    def get_dense_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history\n",
    "    \n",
    "    def transform_label(self,y):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(y)\n",
    "        self.classes = le.classes_\n",
    "        y_prepared = to_categorical(le.transform(y), self.num_classes)\n",
    "        return y_prepared\n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "    \n",
    "    def reverse_predicitions_to_label(self,predictions):\n",
    "        labels = list()\n",
    "        for prediction in predictions:\n",
    "\n",
    "            #prediction tem a quantidade target.\n",
    "            #em particular, são 5: \"DIFICULDADE\",\"EXATAS\",\"MUITO BOM\"\n",
    "            for i in range(0, len(prediction)):\n",
    "                if prediction[i] >= 0.5:\n",
    "                    labels.append(self.classes[i])\n",
    "        return labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_s,num_classes, batch_size, epochs, activation, prepare_data\n",
    "model = DenseModel(9,5,900,2500,tf.keras.layers.ReLU(negative_slope=0.15,max_value=1.0),prepare_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train e Y_train serão dividos dentro do modelo para extrair X_val e Y_val, por isso test_size é pequeno aqui\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da nossa pipeline para armazenamento no Watson Machine Learning:\n",
    "my_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('prepare_data', prepare_data),\n",
    "        ('model', model),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/900\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.6782 - accuracy: 0.1976 - val_loss: 1.6708 - val_accuracy: 0.1964\n",
      "Epoch 2/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6588 - accuracy: 0.2078 - val_loss: 1.6529 - val_accuracy: 0.2092\n",
      "Epoch 3/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6412 - accuracy: 0.2235 - val_loss: 1.6365 - val_accuracy: 0.2214\n",
      "Epoch 4/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6248 - accuracy: 0.2340 - val_loss: 1.6209 - val_accuracy: 0.2392\n",
      "Epoch 5/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.6094 - accuracy: 0.2534 - val_loss: 1.6062 - val_accuracy: 0.2531\n",
      "Epoch 6/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5947 - accuracy: 0.2637 - val_loss: 1.5919 - val_accuracy: 0.2667\n",
      "Epoch 7/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5803 - accuracy: 0.2728 - val_loss: 1.5773 - val_accuracy: 0.2839\n",
      "Epoch 8/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5649 - accuracy: 0.2897 - val_loss: 1.5610 - val_accuracy: 0.2931\n",
      "Epoch 9/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5474 - accuracy: 0.2993 - val_loss: 1.5432 - val_accuracy: 0.3186\n",
      "Epoch 10/900\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.5287 - accuracy: 0.3376 - val_loss: 1.5249 - val_accuracy: 0.3636\n",
      "Epoch 11/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5095 - accuracy: 0.3849 - val_loss: 1.5065 - val_accuracy: 0.4089\n",
      "Epoch 12/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4899 - accuracy: 0.4363 - val_loss: 1.4876 - val_accuracy: 0.4567\n",
      "Epoch 13/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.4701 - accuracy: 0.4798 - val_loss: 1.4687 - val_accuracy: 0.5064\n",
      "Epoch 14/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4506 - accuracy: 0.5206 - val_loss: 1.4498 - val_accuracy: 0.5403\n",
      "Epoch 15/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4309 - accuracy: 0.5480 - val_loss: 1.4306 - val_accuracy: 0.5594\n",
      "Epoch 16/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4113 - accuracy: 0.5615 - val_loss: 1.4110 - val_accuracy: 0.5706\n",
      "Epoch 17/900\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.3908 - accuracy: 0.5708 - val_loss: 1.3903 - val_accuracy: 0.5800\n",
      "Epoch 18/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.3690 - accuracy: 0.5866 - val_loss: 1.3677 - val_accuracy: 0.5994\n",
      "Epoch 19/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3453 - accuracy: 0.6058 - val_loss: 1.3428 - val_accuracy: 0.6117\n",
      "Epoch 20/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3197 - accuracy: 0.6176 - val_loss: 1.3160 - val_accuracy: 0.6239\n",
      "Epoch 21/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2918 - accuracy: 0.6269 - val_loss: 1.2869 - val_accuracy: 0.6211\n",
      "Epoch 22/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2628 - accuracy: 0.6206 - val_loss: 1.2576 - val_accuracy: 0.6186\n",
      "Epoch 23/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2341 - accuracy: 0.6201 - val_loss: 1.2295 - val_accuracy: 0.6192\n",
      "Epoch 24/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2072 - accuracy: 0.6207 - val_loss: 1.2038 - val_accuracy: 0.6189\n",
      "Epoch 25/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1829 - accuracy: 0.6210 - val_loss: 1.1810 - val_accuracy: 0.6189\n",
      "Epoch 26/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1614 - accuracy: 0.6214 - val_loss: 1.1617 - val_accuracy: 0.6194\n",
      "Epoch 27/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1436 - accuracy: 0.6216 - val_loss: 1.1455 - val_accuracy: 0.6206\n",
      "Epoch 28/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1287 - accuracy: 0.6217 - val_loss: 1.1321 - val_accuracy: 0.6206\n",
      "Epoch 29/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1164 - accuracy: 0.6219 - val_loss: 1.1209 - val_accuracy: 0.6208\n",
      "Epoch 30/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1060 - accuracy: 0.6220 - val_loss: 1.1113 - val_accuracy: 0.6208\n",
      "Epoch 31/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0974 - accuracy: 0.6221 - val_loss: 1.1037 - val_accuracy: 0.6208\n",
      "Epoch 32/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0904 - accuracy: 0.6221 - val_loss: 1.0973 - val_accuracy: 0.6208\n",
      "Epoch 33/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0844 - accuracy: 0.6219 - val_loss: 1.0913 - val_accuracy: 0.6208\n",
      "Epoch 34/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0788 - accuracy: 0.6221 - val_loss: 1.0857 - val_accuracy: 0.6208\n",
      "Epoch 35/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0734 - accuracy: 0.6220 - val_loss: 1.0802 - val_accuracy: 0.6208\n",
      "Epoch 36/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0681 - accuracy: 0.6220 - val_loss: 1.0748 - val_accuracy: 0.6208\n",
      "Epoch 37/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0630 - accuracy: 0.6220 - val_loss: 1.0695 - val_accuracy: 0.6208\n",
      "Epoch 38/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0580 - accuracy: 0.6221 - val_loss: 1.0645 - val_accuracy: 0.6208\n",
      "Epoch 39/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0531 - accuracy: 0.6221 - val_loss: 1.0597 - val_accuracy: 0.6208\n",
      "Epoch 40/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0484 - accuracy: 0.6221 - val_loss: 1.0550 - val_accuracy: 0.6208\n",
      "Epoch 41/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0440 - accuracy: 0.6221 - val_loss: 1.0506 - val_accuracy: 0.6208\n",
      "Epoch 42/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0397 - accuracy: 0.6221 - val_loss: 1.0463 - val_accuracy: 0.6208\n",
      "Epoch 43/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0355 - accuracy: 0.6221 - val_loss: 1.0421 - val_accuracy: 0.6208\n",
      "Epoch 44/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0315 - accuracy: 0.6221 - val_loss: 1.0381 - val_accuracy: 0.6208\n",
      "Epoch 45/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0276 - accuracy: 0.6221 - val_loss: 1.0341 - val_accuracy: 0.6208\n",
      "Epoch 46/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0237 - accuracy: 0.6221 - val_loss: 1.0303 - val_accuracy: 0.6211\n",
      "Epoch 47/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0199 - accuracy: 0.6221 - val_loss: 1.0265 - val_accuracy: 0.6211\n",
      "Epoch 48/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0162 - accuracy: 0.6222 - val_loss: 1.0227 - val_accuracy: 0.6211\n",
      "Epoch 49/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0126 - accuracy: 0.6222 - val_loss: 1.0190 - val_accuracy: 0.6211\n",
      "Epoch 50/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0089 - accuracy: 0.6222 - val_loss: 1.0153 - val_accuracy: 0.6211\n",
      "Epoch 51/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0053 - accuracy: 0.6222 - val_loss: 1.0116 - val_accuracy: 0.6211\n",
      "Epoch 52/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0017 - accuracy: 0.6222 - val_loss: 1.0078 - val_accuracy: 0.6211\n",
      "Epoch 53/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9981 - accuracy: 0.6222 - val_loss: 1.0040 - val_accuracy: 0.6211\n",
      "Epoch 54/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9944 - accuracy: 0.6222 - val_loss: 1.0003 - val_accuracy: 0.6211\n",
      "Epoch 55/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9907 - accuracy: 0.6222 - val_loss: 0.9965 - val_accuracy: 0.6211\n",
      "Epoch 56/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9871 - accuracy: 0.6222 - val_loss: 0.9928 - val_accuracy: 0.6211\n",
      "Epoch 57/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9833 - accuracy: 0.6222 - val_loss: 0.9890 - val_accuracy: 0.6211\n",
      "Epoch 58/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9796 - accuracy: 0.6222 - val_loss: 0.9852 - val_accuracy: 0.6211\n",
      "Epoch 59/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9758 - accuracy: 0.6222 - val_loss: 0.9814 - val_accuracy: 0.6211\n",
      "Epoch 60/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9720 - accuracy: 0.6222 - val_loss: 0.9776 - val_accuracy: 0.6211\n",
      "Epoch 61/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9682 - accuracy: 0.6222 - val_loss: 0.9739 - val_accuracy: 0.6211\n",
      "Epoch 62/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9645 - accuracy: 0.6227 - val_loss: 0.9701 - val_accuracy: 0.6214\n",
      "Epoch 63/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9608 - accuracy: 0.6234 - val_loss: 0.9664 - val_accuracy: 0.6228\n",
      "Epoch 64/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9571 - accuracy: 0.6247 - val_loss: 0.9628 - val_accuracy: 0.6247\n",
      "Epoch 65/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9534 - accuracy: 0.6269 - val_loss: 0.9592 - val_accuracy: 0.6264\n",
      "Epoch 66/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9498 - accuracy: 0.6293 - val_loss: 0.9555 - val_accuracy: 0.6286\n",
      "Epoch 67/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9461 - accuracy: 0.6326 - val_loss: 0.9520 - val_accuracy: 0.6308\n",
      "Epoch 68/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9425 - accuracy: 0.6349 - val_loss: 0.9483 - val_accuracy: 0.6322\n",
      "Epoch 69/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9388 - accuracy: 0.6363 - val_loss: 0.9447 - val_accuracy: 0.6336\n",
      "Epoch 70/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9353 - accuracy: 0.6372 - val_loss: 0.9411 - val_accuracy: 0.6356\n",
      "Epoch 71/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9317 - accuracy: 0.6398 - val_loss: 0.9375 - val_accuracy: 0.6358\n",
      "Epoch 72/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9279 - accuracy: 0.6390 - val_loss: 0.9340 - val_accuracy: 0.6356\n",
      "Epoch 73/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9242 - accuracy: 0.6397 - val_loss: 0.9302 - val_accuracy: 0.6364\n",
      "Epoch 74/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9205 - accuracy: 0.6424 - val_loss: 0.9266 - val_accuracy: 0.6378\n",
      "Epoch 75/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9168 - accuracy: 0.6433 - val_loss: 0.9229 - val_accuracy: 0.6375\n",
      "Epoch 76/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9132 - accuracy: 0.6433 - val_loss: 0.9192 - val_accuracy: 0.6386\n",
      "Epoch 77/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9095 - accuracy: 0.6446 - val_loss: 0.9156 - val_accuracy: 0.6403\n",
      "Epoch 78/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9058 - accuracy: 0.6463 - val_loss: 0.9119 - val_accuracy: 0.6411\n",
      "Epoch 79/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9021 - accuracy: 0.6463 - val_loss: 0.9083 - val_accuracy: 0.6408\n",
      "Epoch 80/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8984 - accuracy: 0.6466 - val_loss: 0.9045 - val_accuracy: 0.6425\n",
      "Epoch 81/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8947 - accuracy: 0.6496 - val_loss: 0.9008 - val_accuracy: 0.6439\n",
      "Epoch 82/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8909 - accuracy: 0.6497 - val_loss: 0.8971 - val_accuracy: 0.6436\n",
      "Epoch 83/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8872 - accuracy: 0.6499 - val_loss: 0.8934 - val_accuracy: 0.6444\n",
      "Epoch 84/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8835 - accuracy: 0.6521 - val_loss: 0.8897 - val_accuracy: 0.6467\n",
      "Epoch 85/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8798 - accuracy: 0.6528 - val_loss: 0.8860 - val_accuracy: 0.6467\n",
      "Epoch 86/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8760 - accuracy: 0.6547 - val_loss: 0.8823 - val_accuracy: 0.6494\n",
      "Epoch 87/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8723 - accuracy: 0.6562 - val_loss: 0.8786 - val_accuracy: 0.6506\n",
      "Epoch 88/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8686 - accuracy: 0.6584 - val_loss: 0.8750 - val_accuracy: 0.6508\n",
      "Epoch 89/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8648 - accuracy: 0.6589 - val_loss: 0.8713 - val_accuracy: 0.6525\n",
      "Epoch 90/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8611 - accuracy: 0.6617 - val_loss: 0.8676 - val_accuracy: 0.6539\n",
      "Epoch 91/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8574 - accuracy: 0.6627 - val_loss: 0.8640 - val_accuracy: 0.6558\n",
      "Epoch 92/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8537 - accuracy: 0.6647 - val_loss: 0.8604 - val_accuracy: 0.6589\n",
      "Epoch 93/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8501 - accuracy: 0.6685 - val_loss: 0.8568 - val_accuracy: 0.6600\n",
      "Epoch 94/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8464 - accuracy: 0.6690 - val_loss: 0.8532 - val_accuracy: 0.6628\n",
      "Epoch 95/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8428 - accuracy: 0.6718 - val_loss: 0.8496 - val_accuracy: 0.6650\n",
      "Epoch 96/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8390 - accuracy: 0.6724 - val_loss: 0.8462 - val_accuracy: 0.6656\n",
      "Epoch 97/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8355 - accuracy: 0.6763 - val_loss: 0.8426 - val_accuracy: 0.6708\n",
      "Epoch 98/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8319 - accuracy: 0.6788 - val_loss: 0.8391 - val_accuracy: 0.6697\n",
      "Epoch 99/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8284 - accuracy: 0.6765 - val_loss: 0.8357 - val_accuracy: 0.6714\n",
      "Epoch 100/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8247 - accuracy: 0.6821 - val_loss: 0.8322 - val_accuracy: 0.6772\n",
      "Epoch 101/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8212 - accuracy: 0.6837 - val_loss: 0.8289 - val_accuracy: 0.6750\n",
      "Epoch 102/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8178 - accuracy: 0.6848 - val_loss: 0.8253 - val_accuracy: 0.6797\n",
      "Epoch 103/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8143 - accuracy: 0.6846 - val_loss: 0.8220 - val_accuracy: 0.6794\n",
      "Epoch 104/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8108 - accuracy: 0.6898 - val_loss: 0.8185 - val_accuracy: 0.6853\n",
      "Epoch 105/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8074 - accuracy: 0.6919 - val_loss: 0.8155 - val_accuracy: 0.6844\n",
      "Epoch 106/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8040 - accuracy: 0.6917 - val_loss: 0.8120 - val_accuracy: 0.6883\n",
      "Epoch 107/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8005 - accuracy: 0.6951 - val_loss: 0.8088 - val_accuracy: 0.6900\n",
      "Epoch 108/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7972 - accuracy: 0.6974 - val_loss: 0.8055 - val_accuracy: 0.6917\n",
      "Epoch 109/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7939 - accuracy: 0.6985 - val_loss: 0.8023 - val_accuracy: 0.6953\n",
      "Epoch 110/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7907 - accuracy: 0.7013 - val_loss: 0.7992 - val_accuracy: 0.6978\n",
      "Epoch 111/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7875 - accuracy: 0.7008 - val_loss: 0.7961 - val_accuracy: 0.6986\n",
      "Epoch 112/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7843 - accuracy: 0.7047 - val_loss: 0.7930 - val_accuracy: 0.7025\n",
      "Epoch 113/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7810 - accuracy: 0.7055 - val_loss: 0.7901 - val_accuracy: 0.7011\n",
      "Epoch 114/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7779 - accuracy: 0.7072 - val_loss: 0.7869 - val_accuracy: 0.7042\n",
      "Epoch 115/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7748 - accuracy: 0.7099 - val_loss: 0.7839 - val_accuracy: 0.7058\n",
      "Epoch 116/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7718 - accuracy: 0.7106 - val_loss: 0.7809 - val_accuracy: 0.7069\n",
      "Epoch 117/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7687 - accuracy: 0.7137 - val_loss: 0.7779 - val_accuracy: 0.7100\n",
      "Epoch 118/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7656 - accuracy: 0.7147 - val_loss: 0.7751 - val_accuracy: 0.7094\n",
      "Epoch 119/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7626 - accuracy: 0.7147 - val_loss: 0.7721 - val_accuracy: 0.7119\n",
      "Epoch 120/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7596 - accuracy: 0.7175 - val_loss: 0.7692 - val_accuracy: 0.7142\n",
      "Epoch 121/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7566 - accuracy: 0.7219 - val_loss: 0.7663 - val_accuracy: 0.7139\n",
      "Epoch 122/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7534 - accuracy: 0.7208 - val_loss: 0.7632 - val_accuracy: 0.7147\n",
      "Epoch 123/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7502 - accuracy: 0.7215 - val_loss: 0.7599 - val_accuracy: 0.7181\n",
      "Epoch 124/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7470 - accuracy: 0.7254 - val_loss: 0.7568 - val_accuracy: 0.7194\n",
      "Epoch 125/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7438 - accuracy: 0.7257 - val_loss: 0.7537 - val_accuracy: 0.7206\n",
      "Epoch 126/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7408 - accuracy: 0.7275 - val_loss: 0.7509 - val_accuracy: 0.7211\n",
      "Epoch 127/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7378 - accuracy: 0.7278 - val_loss: 0.7481 - val_accuracy: 0.7228\n",
      "Epoch 128/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7350 - accuracy: 0.7294 - val_loss: 0.7453 - val_accuracy: 0.7239\n",
      "Epoch 129/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7322 - accuracy: 0.7342 - val_loss: 0.7427 - val_accuracy: 0.7269\n",
      "Epoch 130/900\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7295 - accuracy: 0.7337 - val_loss: 0.7401 - val_accuracy: 0.7269\n",
      "Epoch 131/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7271 - accuracy: 0.7369 - val_loss: 0.7375 - val_accuracy: 0.7272\n",
      "Epoch 132/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7243 - accuracy: 0.7337 - val_loss: 0.7350 - val_accuracy: 0.7289\n",
      "Epoch 133/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7214 - accuracy: 0.7390 - val_loss: 0.7323 - val_accuracy: 0.7344\n",
      "Epoch 134/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7191 - accuracy: 0.7367 - val_loss: 0.7300 - val_accuracy: 0.7297\n",
      "Epoch 135/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7163 - accuracy: 0.7395 - val_loss: 0.7275 - val_accuracy: 0.7381\n",
      "Epoch 136/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7141 - accuracy: 0.7420 - val_loss: 0.7253 - val_accuracy: 0.7306\n",
      "Epoch 137/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7116 - accuracy: 0.7412 - val_loss: 0.7227 - val_accuracy: 0.7392\n",
      "Epoch 138/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7093 - accuracy: 0.7423 - val_loss: 0.7205 - val_accuracy: 0.7350\n",
      "Epoch 139/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7070 - accuracy: 0.7442 - val_loss: 0.7182 - val_accuracy: 0.7400\n",
      "Epoch 140/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7047 - accuracy: 0.7440 - val_loss: 0.7162 - val_accuracy: 0.7361\n",
      "Epoch 141/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7023 - accuracy: 0.7449 - val_loss: 0.7138 - val_accuracy: 0.7422\n",
      "Epoch 142/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7004 - accuracy: 0.7458 - val_loss: 0.7118 - val_accuracy: 0.7381\n",
      "Epoch 143/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6982 - accuracy: 0.7467 - val_loss: 0.7096 - val_accuracy: 0.7403\n",
      "Epoch 144/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6960 - accuracy: 0.7470 - val_loss: 0.7075 - val_accuracy: 0.7414\n",
      "Epoch 145/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6941 - accuracy: 0.7502 - val_loss: 0.7055 - val_accuracy: 0.7417\n",
      "Epoch 146/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6921 - accuracy: 0.7467 - val_loss: 0.7036 - val_accuracy: 0.7400\n",
      "Epoch 147/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6899 - accuracy: 0.7506 - val_loss: 0.7016 - val_accuracy: 0.7433\n",
      "Epoch 148/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6880 - accuracy: 0.7520 - val_loss: 0.6999 - val_accuracy: 0.7442\n",
      "Epoch 149/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6861 - accuracy: 0.7513 - val_loss: 0.6979 - val_accuracy: 0.7431\n",
      "Epoch 150/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6842 - accuracy: 0.7515 - val_loss: 0.6961 - val_accuracy: 0.7444\n",
      "Epoch 151/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.7538 - val_loss: 0.6942 - val_accuracy: 0.7458\n",
      "Epoch 152/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6805 - accuracy: 0.7530 - val_loss: 0.6925 - val_accuracy: 0.7469\n",
      "Epoch 153/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6787 - accuracy: 0.7547 - val_loss: 0.6907 - val_accuracy: 0.7483\n",
      "Epoch 154/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6771 - accuracy: 0.7554 - val_loss: 0.6891 - val_accuracy: 0.7464\n",
      "Epoch 155/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6754 - accuracy: 0.7533 - val_loss: 0.6874 - val_accuracy: 0.7483\n",
      "Epoch 156/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6736 - accuracy: 0.7581 - val_loss: 0.6857 - val_accuracy: 0.7483\n",
      "Epoch 157/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6719 - accuracy: 0.7552 - val_loss: 0.6842 - val_accuracy: 0.7467\n",
      "Epoch 158/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6703 - accuracy: 0.7560 - val_loss: 0.6825 - val_accuracy: 0.7522\n",
      "Epoch 159/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6687 - accuracy: 0.7610 - val_loss: 0.6809 - val_accuracy: 0.7492\n",
      "Epoch 160/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6671 - accuracy: 0.7573 - val_loss: 0.6794 - val_accuracy: 0.7492\n",
      "Epoch 161/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6656 - accuracy: 0.7605 - val_loss: 0.6778 - val_accuracy: 0.7506\n",
      "Epoch 162/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6640 - accuracy: 0.7591 - val_loss: 0.6765 - val_accuracy: 0.7508\n",
      "Epoch 163/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6625 - accuracy: 0.7598 - val_loss: 0.6749 - val_accuracy: 0.7536\n",
      "Epoch 164/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6611 - accuracy: 0.7614 - val_loss: 0.6735 - val_accuracy: 0.7503\n",
      "Epoch 165/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6597 - accuracy: 0.7610 - val_loss: 0.6721 - val_accuracy: 0.7539\n",
      "Epoch 166/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6583 - accuracy: 0.7608 - val_loss: 0.6708 - val_accuracy: 0.7558\n",
      "Epoch 167/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6569 - accuracy: 0.7639 - val_loss: 0.6693 - val_accuracy: 0.7561\n",
      "Epoch 168/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6556 - accuracy: 0.7596 - val_loss: 0.6681 - val_accuracy: 0.7508\n",
      "Epoch 169/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6542 - accuracy: 0.7629 - val_loss: 0.6668 - val_accuracy: 0.7586\n",
      "Epoch 170/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6529 - accuracy: 0.7635 - val_loss: 0.6655 - val_accuracy: 0.7564\n",
      "Epoch 171/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6517 - accuracy: 0.7631 - val_loss: 0.6642 - val_accuracy: 0.7578\n",
      "Epoch 172/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6502 - accuracy: 0.7639 - val_loss: 0.6634 - val_accuracy: 0.7575\n",
      "Epoch 173/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6491 - accuracy: 0.7645 - val_loss: 0.6619 - val_accuracy: 0.7600\n",
      "Epoch 174/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6479 - accuracy: 0.7646 - val_loss: 0.6606 - val_accuracy: 0.7581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6467 - accuracy: 0.7617 - val_loss: 0.6594 - val_accuracy: 0.7592\n",
      "Epoch 176/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6455 - accuracy: 0.7671 - val_loss: 0.6584 - val_accuracy: 0.7603\n",
      "Epoch 177/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6444 - accuracy: 0.7655 - val_loss: 0.6573 - val_accuracy: 0.7575\n",
      "Epoch 178/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6436 - accuracy: 0.7665 - val_loss: 0.6561 - val_accuracy: 0.7594\n",
      "Epoch 179/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6420 - accuracy: 0.7647 - val_loss: 0.6552 - val_accuracy: 0.7594\n",
      "Epoch 180/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6410 - accuracy: 0.7672 - val_loss: 0.6539 - val_accuracy: 0.7608\n",
      "Epoch 181/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6399 - accuracy: 0.7656 - val_loss: 0.6530 - val_accuracy: 0.7589\n",
      "Epoch 182/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6386 - accuracy: 0.7675 - val_loss: 0.6519 - val_accuracy: 0.7622\n",
      "Epoch 183/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6379 - accuracy: 0.7689 - val_loss: 0.6513 - val_accuracy: 0.7597\n",
      "Epoch 184/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6368 - accuracy: 0.7649 - val_loss: 0.6498 - val_accuracy: 0.7614\n",
      "Epoch 185/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6356 - accuracy: 0.7694 - val_loss: 0.6490 - val_accuracy: 0.7606\n",
      "Epoch 186/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6346 - accuracy: 0.7678 - val_loss: 0.6479 - val_accuracy: 0.7625\n",
      "Epoch 187/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6336 - accuracy: 0.7699 - val_loss: 0.6470 - val_accuracy: 0.7600\n",
      "Epoch 188/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6327 - accuracy: 0.7657 - val_loss: 0.6460 - val_accuracy: 0.7611\n",
      "Epoch 189/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6318 - accuracy: 0.7712 - val_loss: 0.6451 - val_accuracy: 0.7636\n",
      "Epoch 190/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6308 - accuracy: 0.7682 - val_loss: 0.6442 - val_accuracy: 0.7628\n",
      "Epoch 191/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6298 - accuracy: 0.7715 - val_loss: 0.6433 - val_accuracy: 0.7625\n",
      "Epoch 192/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6287 - accuracy: 0.7680 - val_loss: 0.6426 - val_accuracy: 0.7625\n",
      "Epoch 193/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6280 - accuracy: 0.7709 - val_loss: 0.6416 - val_accuracy: 0.7636\n",
      "Epoch 194/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6270 - accuracy: 0.7702 - val_loss: 0.6410 - val_accuracy: 0.7622\n",
      "Epoch 195/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6262 - accuracy: 0.7697 - val_loss: 0.6399 - val_accuracy: 0.7631\n",
      "Epoch 196/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6251 - accuracy: 0.7707 - val_loss: 0.6395 - val_accuracy: 0.7636\n",
      "Epoch 197/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6243 - accuracy: 0.7712 - val_loss: 0.6383 - val_accuracy: 0.7644\n",
      "Epoch 198/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6235 - accuracy: 0.7729 - val_loss: 0.6377 - val_accuracy: 0.7642\n",
      "Epoch 199/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6228 - accuracy: 0.7693 - val_loss: 0.6366 - val_accuracy: 0.7642\n",
      "Epoch 200/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6217 - accuracy: 0.7714 - val_loss: 0.6359 - val_accuracy: 0.7653\n",
      "Epoch 201/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6210 - accuracy: 0.7728 - val_loss: 0.6352 - val_accuracy: 0.7647\n",
      "Epoch 202/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6202 - accuracy: 0.7710 - val_loss: 0.6344 - val_accuracy: 0.7644\n",
      "Epoch 203/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6193 - accuracy: 0.7717 - val_loss: 0.6336 - val_accuracy: 0.7669\n",
      "Epoch 204/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6187 - accuracy: 0.7740 - val_loss: 0.6329 - val_accuracy: 0.7678\n",
      "Epoch 205/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6180 - accuracy: 0.7737 - val_loss: 0.6322 - val_accuracy: 0.7647\n",
      "Epoch 206/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6171 - accuracy: 0.7719 - val_loss: 0.6316 - val_accuracy: 0.7667\n",
      "Epoch 207/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6164 - accuracy: 0.7736 - val_loss: 0.6307 - val_accuracy: 0.7686\n",
      "Epoch 208/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6156 - accuracy: 0.7729 - val_loss: 0.6302 - val_accuracy: 0.7658\n",
      "Epoch 209/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6151 - accuracy: 0.7748 - val_loss: 0.6294 - val_accuracy: 0.7703\n",
      "Epoch 210/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6143 - accuracy: 0.7742 - val_loss: 0.6287 - val_accuracy: 0.7678\n",
      "Epoch 211/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6133 - accuracy: 0.7739 - val_loss: 0.6280 - val_accuracy: 0.7694\n",
      "Epoch 212/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6127 - accuracy: 0.7756 - val_loss: 0.6275 - val_accuracy: 0.7678\n",
      "Epoch 213/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6120 - accuracy: 0.7765 - val_loss: 0.6267 - val_accuracy: 0.7703\n",
      "Epoch 214/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6114 - accuracy: 0.7738 - val_loss: 0.6261 - val_accuracy: 0.7675\n",
      "Epoch 215/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6108 - accuracy: 0.7747 - val_loss: 0.6256 - val_accuracy: 0.7711\n",
      "Epoch 216/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6101 - accuracy: 0.7789 - val_loss: 0.6248 - val_accuracy: 0.7719\n",
      "Epoch 217/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6093 - accuracy: 0.7739 - val_loss: 0.6245 - val_accuracy: 0.7664\n",
      "Epoch 218/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6087 - accuracy: 0.7735 - val_loss: 0.6236 - val_accuracy: 0.7714\n",
      "Epoch 219/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6082 - accuracy: 0.7786 - val_loss: 0.6231 - val_accuracy: 0.7733\n",
      "Epoch 220/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6078 - accuracy: 0.7761 - val_loss: 0.6224 - val_accuracy: 0.7694\n",
      "Epoch 221/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6072 - accuracy: 0.7765 - val_loss: 0.6218 - val_accuracy: 0.7714\n",
      "Epoch 222/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6064 - accuracy: 0.7742 - val_loss: 0.6215 - val_accuracy: 0.7692\n",
      "Epoch 223/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6056 - accuracy: 0.7785 - val_loss: 0.6208 - val_accuracy: 0.7731\n",
      "Epoch 224/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6050 - accuracy: 0.7774 - val_loss: 0.6204 - val_accuracy: 0.7683\n",
      "Epoch 225/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6044 - accuracy: 0.7758 - val_loss: 0.6196 - val_accuracy: 0.7736\n",
      "Epoch 226/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6039 - accuracy: 0.7778 - val_loss: 0.6191 - val_accuracy: 0.7706\n",
      "Epoch 227/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6034 - accuracy: 0.7758 - val_loss: 0.6185 - val_accuracy: 0.7731\n",
      "Epoch 228/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6029 - accuracy: 0.7790 - val_loss: 0.6179 - val_accuracy: 0.7747\n",
      "Epoch 229/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6022 - accuracy: 0.7769 - val_loss: 0.6175 - val_accuracy: 0.7714\n",
      "Epoch 230/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6017 - accuracy: 0.7782 - val_loss: 0.6169 - val_accuracy: 0.7739\n",
      "Epoch 231/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6011 - accuracy: 0.7772 - val_loss: 0.6164 - val_accuracy: 0.7717\n",
      "Epoch 232/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6005 - accuracy: 0.7795 - val_loss: 0.6159 - val_accuracy: 0.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5999 - accuracy: 0.7794 - val_loss: 0.6154 - val_accuracy: 0.7722\n",
      "Epoch 234/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5994 - accuracy: 0.7789 - val_loss: 0.6148 - val_accuracy: 0.7742\n",
      "Epoch 235/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5989 - accuracy: 0.7794 - val_loss: 0.6144 - val_accuracy: 0.7728\n",
      "Epoch 236/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5984 - accuracy: 0.7789 - val_loss: 0.6139 - val_accuracy: 0.7742\n",
      "Epoch 237/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5978 - accuracy: 0.7794 - val_loss: 0.6134 - val_accuracy: 0.7731\n",
      "Epoch 238/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5973 - accuracy: 0.7777 - val_loss: 0.6129 - val_accuracy: 0.7736\n",
      "Epoch 239/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5968 - accuracy: 0.7795 - val_loss: 0.6124 - val_accuracy: 0.7750\n",
      "Epoch 240/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5964 - accuracy: 0.7806 - val_loss: 0.6119 - val_accuracy: 0.7744\n",
      "Epoch 241/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5959 - accuracy: 0.7780 - val_loss: 0.6115 - val_accuracy: 0.7739\n",
      "Epoch 242/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5954 - accuracy: 0.7801 - val_loss: 0.6110 - val_accuracy: 0.7744\n",
      "Epoch 243/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5949 - accuracy: 0.7794 - val_loss: 0.6107 - val_accuracy: 0.7731\n",
      "Epoch 244/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5944 - accuracy: 0.7793 - val_loss: 0.6101 - val_accuracy: 0.7742\n",
      "Epoch 245/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5939 - accuracy: 0.7801 - val_loss: 0.6097 - val_accuracy: 0.7739\n",
      "Epoch 246/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5935 - accuracy: 0.7790 - val_loss: 0.6093 - val_accuracy: 0.7739\n",
      "Epoch 247/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5931 - accuracy: 0.7802 - val_loss: 0.6088 - val_accuracy: 0.7744\n",
      "Epoch 248/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5928 - accuracy: 0.7796 - val_loss: 0.6084 - val_accuracy: 0.7742\n",
      "Epoch 249/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5923 - accuracy: 0.7803 - val_loss: 0.6080 - val_accuracy: 0.7731\n",
      "Epoch 250/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5916 - accuracy: 0.7798 - val_loss: 0.6075 - val_accuracy: 0.7747\n",
      "Epoch 251/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5913 - accuracy: 0.7799 - val_loss: 0.6072 - val_accuracy: 0.7731\n",
      "Epoch 252/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5909 - accuracy: 0.7806 - val_loss: 0.6067 - val_accuracy: 0.7747\n",
      "Epoch 253/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5904 - accuracy: 0.7805 - val_loss: 0.6064 - val_accuracy: 0.7728\n",
      "Epoch 254/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5901 - accuracy: 0.7794 - val_loss: 0.6059 - val_accuracy: 0.7761\n",
      "Epoch 255/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5896 - accuracy: 0.7819 - val_loss: 0.6057 - val_accuracy: 0.7725\n",
      "Epoch 256/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5893 - accuracy: 0.7800 - val_loss: 0.6051 - val_accuracy: 0.7758\n",
      "Epoch 257/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5888 - accuracy: 0.7815 - val_loss: 0.6049 - val_accuracy: 0.7728\n",
      "Epoch 258/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5884 - accuracy: 0.7794 - val_loss: 0.6043 - val_accuracy: 0.7750\n",
      "Epoch 259/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5882 - accuracy: 0.7831 - val_loss: 0.6040 - val_accuracy: 0.7736\n",
      "Epoch 260/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5877 - accuracy: 0.7798 - val_loss: 0.6037 - val_accuracy: 0.7725\n",
      "Epoch 261/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5872 - accuracy: 0.7809 - val_loss: 0.6032 - val_accuracy: 0.7758\n",
      "Epoch 262/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5868 - accuracy: 0.7805 - val_loss: 0.6031 - val_accuracy: 0.7728\n",
      "Epoch 263/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5864 - accuracy: 0.7812 - val_loss: 0.6025 - val_accuracy: 0.7756\n",
      "Epoch 264/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5860 - accuracy: 0.7817 - val_loss: 0.6022 - val_accuracy: 0.7717\n",
      "Epoch 265/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5856 - accuracy: 0.7813 - val_loss: 0.6018 - val_accuracy: 0.7736\n",
      "Epoch 266/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5853 - accuracy: 0.7811 - val_loss: 0.6014 - val_accuracy: 0.7728\n",
      "Epoch 267/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5850 - accuracy: 0.7819 - val_loss: 0.6011 - val_accuracy: 0.7753\n",
      "Epoch 268/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5845 - accuracy: 0.7810 - val_loss: 0.6010 - val_accuracy: 0.7719\n",
      "Epoch 269/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5842 - accuracy: 0.7808 - val_loss: 0.6003 - val_accuracy: 0.7756\n",
      "Epoch 270/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5838 - accuracy: 0.7822 - val_loss: 0.6001 - val_accuracy: 0.7717\n",
      "Epoch 271/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5835 - accuracy: 0.7807 - val_loss: 0.5996 - val_accuracy: 0.7736\n",
      "Epoch 272/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5831 - accuracy: 0.7824 - val_loss: 0.5994 - val_accuracy: 0.7725\n",
      "Epoch 273/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5826 - accuracy: 0.7815 - val_loss: 0.5990 - val_accuracy: 0.7714\n",
      "Epoch 274/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5823 - accuracy: 0.7816 - val_loss: 0.5987 - val_accuracy: 0.7711\n",
      "Epoch 275/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5820 - accuracy: 0.7826 - val_loss: 0.5983 - val_accuracy: 0.7747\n",
      "Epoch 276/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5817 - accuracy: 0.7808 - val_loss: 0.5980 - val_accuracy: 0.7731\n",
      "Epoch 277/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5813 - accuracy: 0.7831 - val_loss: 0.5977 - val_accuracy: 0.7739\n",
      "Epoch 278/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5810 - accuracy: 0.7820 - val_loss: 0.5975 - val_accuracy: 0.7708\n",
      "Epoch 279/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5805 - accuracy: 0.7825 - val_loss: 0.5970 - val_accuracy: 0.7742\n",
      "Epoch 280/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5803 - accuracy: 0.7827 - val_loss: 0.5969 - val_accuracy: 0.7714\n",
      "Epoch 281/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5799 - accuracy: 0.7819 - val_loss: 0.5964 - val_accuracy: 0.7728\n",
      "Epoch 282/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5795 - accuracy: 0.7828 - val_loss: 0.5962 - val_accuracy: 0.7725\n",
      "Epoch 283/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5793 - accuracy: 0.7826 - val_loss: 0.5958 - val_accuracy: 0.7719\n",
      "Epoch 284/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5789 - accuracy: 0.7828 - val_loss: 0.5955 - val_accuracy: 0.7728\n",
      "Epoch 285/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5786 - accuracy: 0.7833 - val_loss: 0.5952 - val_accuracy: 0.7739\n",
      "Epoch 286/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5783 - accuracy: 0.7827 - val_loss: 0.5949 - val_accuracy: 0.7711\n",
      "Epoch 287/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5780 - accuracy: 0.7821 - val_loss: 0.5946 - val_accuracy: 0.7733\n",
      "Epoch 288/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5777 - accuracy: 0.7837 - val_loss: 0.5944 - val_accuracy: 0.7742\n",
      "Epoch 289/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5774 - accuracy: 0.7823 - val_loss: 0.5940 - val_accuracy: 0.7719\n",
      "Epoch 290/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5774 - accuracy: 0.7848 - val_loss: 0.5937 - val_accuracy: 0.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5771 - accuracy: 0.7827 - val_loss: 0.5936 - val_accuracy: 0.7742\n",
      "Epoch 292/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5767 - accuracy: 0.7849 - val_loss: 0.5932 - val_accuracy: 0.7753\n",
      "Epoch 293/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5766 - accuracy: 0.7831 - val_loss: 0.5931 - val_accuracy: 0.7736\n",
      "Epoch 294/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5760 - accuracy: 0.7846 - val_loss: 0.5926 - val_accuracy: 0.7750\n",
      "Epoch 295/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5755 - accuracy: 0.7835 - val_loss: 0.5925 - val_accuracy: 0.7742\n",
      "Epoch 296/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5754 - accuracy: 0.7843 - val_loss: 0.5921 - val_accuracy: 0.7769\n",
      "Epoch 297/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5750 - accuracy: 0.7834 - val_loss: 0.5918 - val_accuracy: 0.7725\n",
      "Epoch 298/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5747 - accuracy: 0.7831 - val_loss: 0.5914 - val_accuracy: 0.7750\n",
      "Epoch 299/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5744 - accuracy: 0.7839 - val_loss: 0.5912 - val_accuracy: 0.7756\n",
      "Epoch 300/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5741 - accuracy: 0.7854 - val_loss: 0.5909 - val_accuracy: 0.7742\n",
      "Epoch 301/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5740 - accuracy: 0.7826 - val_loss: 0.5907 - val_accuracy: 0.7736\n",
      "Epoch 302/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5735 - accuracy: 0.7835 - val_loss: 0.5903 - val_accuracy: 0.7778\n",
      "Epoch 303/900\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5734 - accuracy: 0.7848 - val_loss: 0.5901 - val_accuracy: 0.7767\n",
      "Epoch 304/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5730 - accuracy: 0.7847 - val_loss: 0.5898 - val_accuracy: 0.7742\n",
      "Epoch 305/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5728 - accuracy: 0.7838 - val_loss: 0.5896 - val_accuracy: 0.7750\n",
      "Epoch 306/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5726 - accuracy: 0.7860 - val_loss: 0.5893 - val_accuracy: 0.7767\n",
      "Epoch 307/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5722 - accuracy: 0.7852 - val_loss: 0.5891 - val_accuracy: 0.7744\n",
      "Epoch 308/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5720 - accuracy: 0.7837 - val_loss: 0.5888 - val_accuracy: 0.7753\n",
      "Epoch 309/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5717 - accuracy: 0.7856 - val_loss: 0.5885 - val_accuracy: 0.7758\n",
      "Epoch 310/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5715 - accuracy: 0.7842 - val_loss: 0.5883 - val_accuracy: 0.7756\n",
      "Epoch 311/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5714 - accuracy: 0.7861 - val_loss: 0.5880 - val_accuracy: 0.7764\n",
      "Epoch 312/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5709 - accuracy: 0.7851 - val_loss: 0.5880 - val_accuracy: 0.7761\n",
      "Epoch 313/900\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5707 - accuracy: 0.7843 - val_loss: 0.5875 - val_accuracy: 0.7775\n",
      "Epoch 314/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5704 - accuracy: 0.7848 - val_loss: 0.5873 - val_accuracy: 0.7758\n",
      "Epoch 315/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5701 - accuracy: 0.7857 - val_loss: 0.5871 - val_accuracy: 0.7764\n",
      "Epoch 316/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5699 - accuracy: 0.7850 - val_loss: 0.5868 - val_accuracy: 0.7764\n",
      "Epoch 317/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5697 - accuracy: 0.7856 - val_loss: 0.5866 - val_accuracy: 0.7761\n",
      "Epoch 318/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5695 - accuracy: 0.7868 - val_loss: 0.5863 - val_accuracy: 0.7764\n",
      "Epoch 319/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5695 - accuracy: 0.7844 - val_loss: 0.5861 - val_accuracy: 0.7761\n",
      "Epoch 320/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5690 - accuracy: 0.7867 - val_loss: 0.5859 - val_accuracy: 0.7769\n",
      "Epoch 321/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5695 - accuracy: 0.7838 - val_loss: 0.5856 - val_accuracy: 0.7767\n",
      "Epoch 322/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5687 - accuracy: 0.7870 - val_loss: 0.5853 - val_accuracy: 0.7767\n",
      "Epoch 323/900\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5684 - accuracy: 0.7849 - val_loss: 0.5853 - val_accuracy: 0.7753\n",
      "Epoch 324/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5682 - accuracy: 0.7863 - val_loss: 0.5849 - val_accuracy: 0.7778\n",
      "Epoch 325/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5677 - accuracy: 0.7858 - val_loss: 0.5850 - val_accuracy: 0.7742\n",
      "Epoch 326/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5676 - accuracy: 0.7852 - val_loss: 0.5844 - val_accuracy: 0.7769\n",
      "Epoch 327/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5674 - accuracy: 0.7874 - val_loss: 0.5844 - val_accuracy: 0.7753\n",
      "Epoch 328/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5676 - accuracy: 0.7844 - val_loss: 0.5841 - val_accuracy: 0.7758\n",
      "Epoch 329/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5670 - accuracy: 0.7870 - val_loss: 0.5838 - val_accuracy: 0.7767\n",
      "Epoch 330/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5668 - accuracy: 0.7852 - val_loss: 0.5836 - val_accuracy: 0.7756\n",
      "Epoch 331/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5665 - accuracy: 0.7866 - val_loss: 0.5834 - val_accuracy: 0.7764\n",
      "Epoch 332/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5662 - accuracy: 0.7862 - val_loss: 0.5832 - val_accuracy: 0.7758\n",
      "Epoch 333/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5660 - accuracy: 0.7857 - val_loss: 0.5829 - val_accuracy: 0.7772\n",
      "Epoch 334/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5660 - accuracy: 0.7870 - val_loss: 0.5828 - val_accuracy: 0.7761\n",
      "Epoch 335/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5659 - accuracy: 0.7867 - val_loss: 0.5825 - val_accuracy: 0.7750\n",
      "Epoch 336/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5654 - accuracy: 0.7852 - val_loss: 0.5824 - val_accuracy: 0.7750\n",
      "Epoch 337/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5651 - accuracy: 0.7871 - val_loss: 0.5820 - val_accuracy: 0.7778\n",
      "Epoch 338/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5649 - accuracy: 0.7865 - val_loss: 0.5819 - val_accuracy: 0.7761\n",
      "Epoch 339/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5646 - accuracy: 0.7865 - val_loss: 0.5816 - val_accuracy: 0.7775\n",
      "Epoch 340/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5646 - accuracy: 0.7874 - val_loss: 0.5815 - val_accuracy: 0.7756\n",
      "Epoch 341/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5644 - accuracy: 0.7845 - val_loss: 0.5812 - val_accuracy: 0.7769\n",
      "Epoch 342/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5641 - accuracy: 0.7882 - val_loss: 0.5809 - val_accuracy: 0.7767\n",
      "Epoch 343/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5638 - accuracy: 0.7868 - val_loss: 0.5809 - val_accuracy: 0.7750\n",
      "Epoch 344/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5637 - accuracy: 0.7858 - val_loss: 0.5805 - val_accuracy: 0.7786\n",
      "Epoch 345/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5635 - accuracy: 0.7879 - val_loss: 0.5804 - val_accuracy: 0.7761\n",
      "Epoch 346/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5632 - accuracy: 0.7853 - val_loss: 0.5802 - val_accuracy: 0.7758\n",
      "Epoch 347/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5632 - accuracy: 0.7880 - val_loss: 0.5799 - val_accuracy: 0.7778\n",
      "Epoch 348/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5630 - accuracy: 0.7851 - val_loss: 0.5798 - val_accuracy: 0.7764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5627 - accuracy: 0.7869 - val_loss: 0.5794 - val_accuracy: 0.7778\n",
      "Epoch 350/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5624 - accuracy: 0.7878 - val_loss: 0.5793 - val_accuracy: 0.7764\n",
      "Epoch 351/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5622 - accuracy: 0.7866 - val_loss: 0.5791 - val_accuracy: 0.7775\n",
      "Epoch 352/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5621 - accuracy: 0.7876 - val_loss: 0.5789 - val_accuracy: 0.7778\n",
      "Epoch 353/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5618 - accuracy: 0.7872 - val_loss: 0.5788 - val_accuracy: 0.7764\n",
      "Epoch 354/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5616 - accuracy: 0.7864 - val_loss: 0.5784 - val_accuracy: 0.7775\n",
      "Epoch 355/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5616 - accuracy: 0.7876 - val_loss: 0.5783 - val_accuracy: 0.7767\n",
      "Epoch 356/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5613 - accuracy: 0.7855 - val_loss: 0.5781 - val_accuracy: 0.7767\n",
      "Epoch 357/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5612 - accuracy: 0.7879 - val_loss: 0.5778 - val_accuracy: 0.7769\n",
      "Epoch 358/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5609 - accuracy: 0.7860 - val_loss: 0.5777 - val_accuracy: 0.7764\n",
      "Epoch 359/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5608 - accuracy: 0.7885 - val_loss: 0.5774 - val_accuracy: 0.7772\n",
      "Epoch 360/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5604 - accuracy: 0.7866 - val_loss: 0.5776 - val_accuracy: 0.7756\n",
      "Epoch 361/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5602 - accuracy: 0.7869 - val_loss: 0.5771 - val_accuracy: 0.7794\n",
      "Epoch 362/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.7877 - val_loss: 0.5769 - val_accuracy: 0.7764\n",
      "Epoch 363/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5599 - accuracy: 0.7867 - val_loss: 0.5766 - val_accuracy: 0.7775\n",
      "Epoch 364/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5597 - accuracy: 0.7874 - val_loss: 0.5764 - val_accuracy: 0.7775\n",
      "Epoch 365/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5596 - accuracy: 0.7872 - val_loss: 0.5763 - val_accuracy: 0.7769\n",
      "Epoch 366/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5594 - accuracy: 0.7885 - val_loss: 0.5761 - val_accuracy: 0.7775\n",
      "Epoch 367/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5591 - accuracy: 0.7867 - val_loss: 0.5761 - val_accuracy: 0.7753\n",
      "Epoch 368/900\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5593 - accuracy: 0.7886 - val_loss: 0.5757 - val_accuracy: 0.7769\n",
      "Epoch 369/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5586 - accuracy: 0.7871 - val_loss: 0.5756 - val_accuracy: 0.7761\n",
      "Epoch 370/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5585 - accuracy: 0.7872 - val_loss: 0.5753 - val_accuracy: 0.7783\n",
      "Epoch 371/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5583 - accuracy: 0.7876 - val_loss: 0.5752 - val_accuracy: 0.7775\n",
      "Epoch 372/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5583 - accuracy: 0.7885 - val_loss: 0.5749 - val_accuracy: 0.7772\n",
      "Epoch 373/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5580 - accuracy: 0.7868 - val_loss: 0.5748 - val_accuracy: 0.7767\n",
      "Epoch 374/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5578 - accuracy: 0.7882 - val_loss: 0.5745 - val_accuracy: 0.7794\n",
      "Epoch 375/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5576 - accuracy: 0.7872 - val_loss: 0.5743 - val_accuracy: 0.7758\n",
      "Epoch 376/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5574 - accuracy: 0.7881 - val_loss: 0.5741 - val_accuracy: 0.7761\n",
      "Epoch 377/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5572 - accuracy: 0.7877 - val_loss: 0.5739 - val_accuracy: 0.7786\n",
      "Epoch 378/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5570 - accuracy: 0.7887 - val_loss: 0.5738 - val_accuracy: 0.7772\n",
      "Epoch 379/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5569 - accuracy: 0.7879 - val_loss: 0.5736 - val_accuracy: 0.7756\n",
      "Epoch 380/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5568 - accuracy: 0.7863 - val_loss: 0.5734 - val_accuracy: 0.7769\n",
      "Epoch 381/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5568 - accuracy: 0.7906 - val_loss: 0.5732 - val_accuracy: 0.7786\n",
      "Epoch 382/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5564 - accuracy: 0.7873 - val_loss: 0.5732 - val_accuracy: 0.7772\n",
      "Epoch 383/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5562 - accuracy: 0.7895 - val_loss: 0.5728 - val_accuracy: 0.7783\n",
      "Epoch 384/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5559 - accuracy: 0.7885 - val_loss: 0.5728 - val_accuracy: 0.7756\n",
      "Epoch 385/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5559 - accuracy: 0.7885 - val_loss: 0.5724 - val_accuracy: 0.7792\n",
      "Epoch 386/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5556 - accuracy: 0.7880 - val_loss: 0.5723 - val_accuracy: 0.7764\n",
      "Epoch 387/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5553 - accuracy: 0.7885 - val_loss: 0.5720 - val_accuracy: 0.7783\n",
      "Epoch 388/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5553 - accuracy: 0.7890 - val_loss: 0.5719 - val_accuracy: 0.7767\n",
      "Epoch 389/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5552 - accuracy: 0.7882 - val_loss: 0.5717 - val_accuracy: 0.7800\n",
      "Epoch 390/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5549 - accuracy: 0.7889 - val_loss: 0.5715 - val_accuracy: 0.7769\n",
      "Epoch 391/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5546 - accuracy: 0.7879 - val_loss: 0.5713 - val_accuracy: 0.7767\n",
      "Epoch 392/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5545 - accuracy: 0.7896 - val_loss: 0.5711 - val_accuracy: 0.7794\n",
      "Epoch 393/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5544 - accuracy: 0.7887 - val_loss: 0.5712 - val_accuracy: 0.7756\n",
      "Epoch 394/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5542 - accuracy: 0.7872 - val_loss: 0.5707 - val_accuracy: 0.7811\n",
      "Epoch 395/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5543 - accuracy: 0.7906 - val_loss: 0.5705 - val_accuracy: 0.7761\n",
      "Epoch 396/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5540 - accuracy: 0.7874 - val_loss: 0.5703 - val_accuracy: 0.7767\n",
      "Epoch 397/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5537 - accuracy: 0.7907 - val_loss: 0.5701 - val_accuracy: 0.7789\n",
      "Epoch 398/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5533 - accuracy: 0.7890 - val_loss: 0.5705 - val_accuracy: 0.7797\n",
      "Epoch 399/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5534 - accuracy: 0.7891 - val_loss: 0.5698 - val_accuracy: 0.7797\n",
      "Epoch 400/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5529 - accuracy: 0.7896 - val_loss: 0.5699 - val_accuracy: 0.7794\n",
      "Epoch 401/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5529 - accuracy: 0.7889 - val_loss: 0.5693 - val_accuracy: 0.7781\n",
      "Epoch 402/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5526 - accuracy: 0.7898 - val_loss: 0.5692 - val_accuracy: 0.7767\n",
      "Epoch 403/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5524 - accuracy: 0.7879 - val_loss: 0.5689 - val_accuracy: 0.7786\n",
      "Epoch 404/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5523 - accuracy: 0.7907 - val_loss: 0.5687 - val_accuracy: 0.7781\n",
      "Epoch 405/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5521 - accuracy: 0.7882 - val_loss: 0.5686 - val_accuracy: 0.7767\n",
      "Epoch 406/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5517 - accuracy: 0.7892 - val_loss: 0.5683 - val_accuracy: 0.7792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5516 - accuracy: 0.7903 - val_loss: 0.5682 - val_accuracy: 0.7783\n",
      "Epoch 408/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5515 - accuracy: 0.7884 - val_loss: 0.5680 - val_accuracy: 0.7767\n",
      "Epoch 409/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5512 - accuracy: 0.7894 - val_loss: 0.5677 - val_accuracy: 0.7794\n",
      "Epoch 410/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5510 - accuracy: 0.7902 - val_loss: 0.5675 - val_accuracy: 0.7778\n",
      "Epoch 411/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5509 - accuracy: 0.7883 - val_loss: 0.5673 - val_accuracy: 0.7786\n",
      "Epoch 412/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5506 - accuracy: 0.7901 - val_loss: 0.5671 - val_accuracy: 0.7786\n",
      "Epoch 413/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5505 - accuracy: 0.7891 - val_loss: 0.5669 - val_accuracy: 0.7803\n",
      "Epoch 414/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5503 - accuracy: 0.7892 - val_loss: 0.5668 - val_accuracy: 0.7781\n",
      "Epoch 415/900\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5501 - accuracy: 0.7897 - val_loss: 0.5666 - val_accuracy: 0.7811\n",
      "Epoch 416/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5499 - accuracy: 0.7890 - val_loss: 0.5662 - val_accuracy: 0.7789\n",
      "Epoch 417/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5497 - accuracy: 0.7899 - val_loss: 0.5660 - val_accuracy: 0.7803\n",
      "Epoch 418/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5496 - accuracy: 0.7903 - val_loss: 0.5658 - val_accuracy: 0.7797\n",
      "Epoch 419/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5495 - accuracy: 0.7879 - val_loss: 0.5657 - val_accuracy: 0.7778\n",
      "Epoch 420/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5493 - accuracy: 0.7901 - val_loss: 0.5654 - val_accuracy: 0.7808\n",
      "Epoch 421/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5490 - accuracy: 0.7883 - val_loss: 0.5652 - val_accuracy: 0.7792\n",
      "Epoch 422/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5487 - accuracy: 0.7903 - val_loss: 0.5649 - val_accuracy: 0.7808\n",
      "Epoch 423/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5486 - accuracy: 0.7899 - val_loss: 0.5647 - val_accuracy: 0.7783\n",
      "Epoch 424/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5484 - accuracy: 0.7912 - val_loss: 0.5644 - val_accuracy: 0.7811\n",
      "Epoch 425/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5485 - accuracy: 0.7901 - val_loss: 0.5643 - val_accuracy: 0.7803\n",
      "Epoch 426/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5480 - accuracy: 0.7908 - val_loss: 0.5640 - val_accuracy: 0.7803\n",
      "Epoch 427/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5479 - accuracy: 0.7888 - val_loss: 0.5639 - val_accuracy: 0.7794\n",
      "Epoch 428/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5476 - accuracy: 0.7910 - val_loss: 0.5635 - val_accuracy: 0.7822\n",
      "Epoch 429/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5474 - accuracy: 0.7899 - val_loss: 0.5634 - val_accuracy: 0.7789\n",
      "Epoch 430/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5472 - accuracy: 0.7896 - val_loss: 0.5630 - val_accuracy: 0.7814\n",
      "Epoch 431/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5470 - accuracy: 0.7901 - val_loss: 0.5629 - val_accuracy: 0.7792\n",
      "Epoch 432/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5468 - accuracy: 0.7894 - val_loss: 0.5626 - val_accuracy: 0.7803\n",
      "Epoch 433/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5466 - accuracy: 0.7903 - val_loss: 0.5624 - val_accuracy: 0.7803\n",
      "Epoch 434/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5464 - accuracy: 0.7897 - val_loss: 0.5621 - val_accuracy: 0.7811\n",
      "Epoch 435/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5463 - accuracy: 0.7911 - val_loss: 0.5619 - val_accuracy: 0.7800\n",
      "Epoch 436/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5462 - accuracy: 0.7903 - val_loss: 0.5616 - val_accuracy: 0.7811\n",
      "Epoch 437/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5458 - accuracy: 0.7915 - val_loss: 0.5614 - val_accuracy: 0.7819\n",
      "Epoch 438/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5457 - accuracy: 0.7899 - val_loss: 0.5612 - val_accuracy: 0.7794\n",
      "Epoch 439/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5454 - accuracy: 0.7904 - val_loss: 0.5608 - val_accuracy: 0.7811\n",
      "Epoch 440/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5453 - accuracy: 0.7906 - val_loss: 0.5606 - val_accuracy: 0.7806\n",
      "Epoch 441/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5448 - accuracy: 0.7903 - val_loss: 0.5605 - val_accuracy: 0.7803\n",
      "Epoch 442/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5448 - accuracy: 0.7906 - val_loss: 0.5601 - val_accuracy: 0.7797\n",
      "Epoch 443/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5445 - accuracy: 0.7908 - val_loss: 0.5598 - val_accuracy: 0.7797\n",
      "Epoch 444/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5444 - accuracy: 0.7911 - val_loss: 0.5597 - val_accuracy: 0.7817\n",
      "Epoch 445/900\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5441 - accuracy: 0.7906 - val_loss: 0.5593 - val_accuracy: 0.7797\n",
      "Epoch 446/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5438 - accuracy: 0.7916 - val_loss: 0.5590 - val_accuracy: 0.7806\n",
      "Epoch 447/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5436 - accuracy: 0.7903 - val_loss: 0.5588 - val_accuracy: 0.7803\n",
      "Epoch 448/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5434 - accuracy: 0.7908 - val_loss: 0.5585 - val_accuracy: 0.7811\n",
      "Epoch 449/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5431 - accuracy: 0.7913 - val_loss: 0.5583 - val_accuracy: 0.7806\n",
      "Epoch 450/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5430 - accuracy: 0.7920 - val_loss: 0.5581 - val_accuracy: 0.7803\n",
      "Epoch 451/900\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5428 - accuracy: 0.7890 - val_loss: 0.5577 - val_accuracy: 0.7800\n",
      "Epoch 452/900\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5424 - accuracy: 0.7923 - val_loss: 0.5574 - val_accuracy: 0.7806\n",
      "Epoch 453/900\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5424 - accuracy: 0.7912 - val_loss: 0.5572 - val_accuracy: 0.7794\n",
      "Epoch 454/900\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5423 - accuracy: 0.7914 - val_loss: 0.5569 - val_accuracy: 0.7819\n",
      "Epoch 455/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5419 - accuracy: 0.7908 - val_loss: 0.5565 - val_accuracy: 0.7808\n",
      "Epoch 456/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5415 - accuracy: 0.7926 - val_loss: 0.5562 - val_accuracy: 0.7797\n",
      "Epoch 457/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5414 - accuracy: 0.7910 - val_loss: 0.5560 - val_accuracy: 0.7828\n",
      "Epoch 458/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5409 - accuracy: 0.7910 - val_loss: 0.5557 - val_accuracy: 0.7811\n",
      "Epoch 459/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5409 - accuracy: 0.7929 - val_loss: 0.5553 - val_accuracy: 0.7803\n",
      "Epoch 460/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5407 - accuracy: 0.7903 - val_loss: 0.5553 - val_accuracy: 0.7789\n",
      "Epoch 461/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5403 - accuracy: 0.7907 - val_loss: 0.5547 - val_accuracy: 0.7803\n",
      "Epoch 462/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5404 - accuracy: 0.7910 - val_loss: 0.5544 - val_accuracy: 0.7789\n",
      "Epoch 463/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5402 - accuracy: 0.7928 - val_loss: 0.5541 - val_accuracy: 0.7811\n",
      "Epoch 464/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5393 - accuracy: 0.7914 - val_loss: 0.5541 - val_accuracy: 0.7792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5392 - accuracy: 0.7919 - val_loss: 0.5534 - val_accuracy: 0.7814\n",
      "Epoch 466/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5389 - accuracy: 0.7924 - val_loss: 0.5532 - val_accuracy: 0.7786\n",
      "Epoch 467/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5387 - accuracy: 0.7906 - val_loss: 0.5529 - val_accuracy: 0.7789\n",
      "Epoch 468/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5384 - accuracy: 0.7916 - val_loss: 0.5525 - val_accuracy: 0.7803\n",
      "Epoch 469/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5381 - accuracy: 0.7928 - val_loss: 0.5523 - val_accuracy: 0.7778\n",
      "Epoch 470/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5378 - accuracy: 0.7906 - val_loss: 0.5519 - val_accuracy: 0.7783\n",
      "Epoch 471/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5375 - accuracy: 0.7919 - val_loss: 0.5515 - val_accuracy: 0.7783\n",
      "Epoch 472/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5372 - accuracy: 0.7924 - val_loss: 0.5512 - val_accuracy: 0.7786\n",
      "Epoch 473/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5370 - accuracy: 0.7910 - val_loss: 0.5509 - val_accuracy: 0.7783\n",
      "Epoch 474/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5369 - accuracy: 0.7928 - val_loss: 0.5506 - val_accuracy: 0.7786\n",
      "Epoch 475/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5366 - accuracy: 0.7912 - val_loss: 0.5502 - val_accuracy: 0.7792\n",
      "Epoch 476/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5362 - accuracy: 0.7933 - val_loss: 0.5499 - val_accuracy: 0.7797\n",
      "Epoch 477/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5360 - accuracy: 0.7915 - val_loss: 0.5497 - val_accuracy: 0.7783\n",
      "Epoch 478/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5357 - accuracy: 0.7920 - val_loss: 0.5493 - val_accuracy: 0.7811\n",
      "Epoch 479/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5354 - accuracy: 0.7905 - val_loss: 0.5490 - val_accuracy: 0.7800\n",
      "Epoch 480/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5350 - accuracy: 0.7935 - val_loss: 0.5486 - val_accuracy: 0.7797\n",
      "Epoch 481/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5349 - accuracy: 0.7912 - val_loss: 0.5485 - val_accuracy: 0.7781\n",
      "Epoch 482/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.7923 - val_loss: 0.5479 - val_accuracy: 0.7794\n",
      "Epoch 483/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5342 - accuracy: 0.7923 - val_loss: 0.5477 - val_accuracy: 0.7786\n",
      "Epoch 484/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5338 - accuracy: 0.7922 - val_loss: 0.5473 - val_accuracy: 0.7808\n",
      "Epoch 485/900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7908 - val_loss: 0.5468 - val_accuracy: 0.7789\n",
      "Epoch 486/900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7940 - val_loss: 0.5467 - val_accuracy: 0.7800\n",
      "Epoch 487/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5330 - accuracy: 0.7917 - val_loss: 0.5462 - val_accuracy: 0.7794\n",
      "Epoch 488/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5325 - accuracy: 0.7922 - val_loss: 0.5460 - val_accuracy: 0.7792\n",
      "Epoch 489/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5323 - accuracy: 0.7926 - val_loss: 0.5456 - val_accuracy: 0.7786\n",
      "Epoch 490/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5320 - accuracy: 0.7926 - val_loss: 0.5453 - val_accuracy: 0.7783\n",
      "Epoch 491/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5317 - accuracy: 0.7917 - val_loss: 0.5449 - val_accuracy: 0.7794\n",
      "Epoch 492/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5316 - accuracy: 0.7937 - val_loss: 0.5446 - val_accuracy: 0.7786\n",
      "Epoch 493/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5313 - accuracy: 0.7905 - val_loss: 0.5443 - val_accuracy: 0.7786\n",
      "Epoch 494/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5308 - accuracy: 0.7921 - val_loss: 0.5439 - val_accuracy: 0.7800\n",
      "Epoch 495/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5306 - accuracy: 0.7931 - val_loss: 0.5436 - val_accuracy: 0.7803\n",
      "Epoch 496/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5304 - accuracy: 0.7915 - val_loss: 0.5433 - val_accuracy: 0.7797\n",
      "Epoch 497/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7927 - val_loss: 0.5430 - val_accuracy: 0.7803\n",
      "Epoch 498/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5299 - accuracy: 0.7909 - val_loss: 0.5426 - val_accuracy: 0.7792\n",
      "Epoch 499/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5295 - accuracy: 0.7931 - val_loss: 0.5424 - val_accuracy: 0.7808\n",
      "Epoch 500/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5293 - accuracy: 0.7924 - val_loss: 0.5422 - val_accuracy: 0.7789\n",
      "Epoch 501/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5291 - accuracy: 0.7915 - val_loss: 0.5417 - val_accuracy: 0.7803\n",
      "Epoch 502/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5289 - accuracy: 0.7934 - val_loss: 0.5416 - val_accuracy: 0.7794\n",
      "Epoch 503/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5285 - accuracy: 0.7908 - val_loss: 0.5410 - val_accuracy: 0.7803\n",
      "Epoch 504/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5282 - accuracy: 0.7924 - val_loss: 0.5408 - val_accuracy: 0.7806\n",
      "Epoch 505/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5280 - accuracy: 0.7933 - val_loss: 0.5404 - val_accuracy: 0.7792\n",
      "Epoch 506/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5277 - accuracy: 0.7904 - val_loss: 0.5402 - val_accuracy: 0.7789\n",
      "Epoch 507/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5274 - accuracy: 0.7935 - val_loss: 0.5397 - val_accuracy: 0.7803\n",
      "Epoch 508/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5272 - accuracy: 0.7903 - val_loss: 0.5395 - val_accuracy: 0.7789\n",
      "Epoch 509/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5268 - accuracy: 0.7938 - val_loss: 0.5393 - val_accuracy: 0.7817\n",
      "Epoch 510/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5265 - accuracy: 0.7919 - val_loss: 0.5390 - val_accuracy: 0.7781\n",
      "Epoch 511/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5265 - accuracy: 0.7928 - val_loss: 0.5386 - val_accuracy: 0.7808\n",
      "Epoch 512/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5260 - accuracy: 0.7917 - val_loss: 0.5384 - val_accuracy: 0.7792\n",
      "Epoch 513/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5260 - accuracy: 0.7926 - val_loss: 0.5382 - val_accuracy: 0.7817\n",
      "Epoch 514/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5256 - accuracy: 0.7922 - val_loss: 0.5378 - val_accuracy: 0.7794\n",
      "Epoch 515/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5253 - accuracy: 0.7929 - val_loss: 0.5376 - val_accuracy: 0.7814\n",
      "Epoch 516/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5251 - accuracy: 0.7931 - val_loss: 0.5375 - val_accuracy: 0.7794\n",
      "Epoch 517/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.7921 - val_loss: 0.5369 - val_accuracy: 0.7817\n",
      "Epoch 518/900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.7928 - val_loss: 0.5368 - val_accuracy: 0.7786\n",
      "Epoch 519/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5242 - accuracy: 0.7913 - val_loss: 0.5363 - val_accuracy: 0.7819\n",
      "Epoch 520/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5239 - accuracy: 0.7936 - val_loss: 0.5363 - val_accuracy: 0.7783\n",
      "Epoch 521/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5237 - accuracy: 0.7906 - val_loss: 0.5358 - val_accuracy: 0.7811\n",
      "Epoch 522/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5235 - accuracy: 0.7939 - val_loss: 0.5357 - val_accuracy: 0.7786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5232 - accuracy: 0.7916 - val_loss: 0.5352 - val_accuracy: 0.7808\n",
      "Epoch 524/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5229 - accuracy: 0.7933 - val_loss: 0.5351 - val_accuracy: 0.7800\n",
      "Epoch 525/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5226 - accuracy: 0.7929 - val_loss: 0.5348 - val_accuracy: 0.7792\n",
      "Epoch 526/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5225 - accuracy: 0.7922 - val_loss: 0.5347 - val_accuracy: 0.7811\n",
      "Epoch 527/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5222 - accuracy: 0.7932 - val_loss: 0.5342 - val_accuracy: 0.7811\n",
      "Epoch 528/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5220 - accuracy: 0.7926 - val_loss: 0.5341 - val_accuracy: 0.7797\n",
      "Epoch 529/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5218 - accuracy: 0.7935 - val_loss: 0.5338 - val_accuracy: 0.7811\n",
      "Epoch 530/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5215 - accuracy: 0.7926 - val_loss: 0.5335 - val_accuracy: 0.7811\n",
      "Epoch 531/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5211 - accuracy: 0.7934 - val_loss: 0.5334 - val_accuracy: 0.7811\n",
      "Epoch 532/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5210 - accuracy: 0.7936 - val_loss: 0.5332 - val_accuracy: 0.7808\n",
      "Epoch 533/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5207 - accuracy: 0.7933 - val_loss: 0.5328 - val_accuracy: 0.7806\n",
      "Epoch 534/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5207 - accuracy: 0.7937 - val_loss: 0.5326 - val_accuracy: 0.7806\n",
      "Epoch 535/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5205 - accuracy: 0.7912 - val_loss: 0.5326 - val_accuracy: 0.7786\n",
      "Epoch 536/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.7940 - val_loss: 0.5322 - val_accuracy: 0.7819\n",
      "Epoch 537/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5199 - accuracy: 0.7929 - val_loss: 0.5322 - val_accuracy: 0.7789\n",
      "Epoch 538/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.7928 - val_loss: 0.5317 - val_accuracy: 0.7817\n",
      "Epoch 539/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5195 - accuracy: 0.7942 - val_loss: 0.5315 - val_accuracy: 0.7808\n",
      "Epoch 540/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5194 - accuracy: 0.7907 - val_loss: 0.5312 - val_accuracy: 0.7817\n",
      "Epoch 541/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5191 - accuracy: 0.7948 - val_loss: 0.5309 - val_accuracy: 0.7811\n",
      "Epoch 542/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5190 - accuracy: 0.7919 - val_loss: 0.5307 - val_accuracy: 0.7822\n",
      "Epoch 543/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5188 - accuracy: 0.7938 - val_loss: 0.5306 - val_accuracy: 0.7828\n",
      "Epoch 544/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5185 - accuracy: 0.7908 - val_loss: 0.5304 - val_accuracy: 0.7792\n",
      "Epoch 545/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5180 - accuracy: 0.7936 - val_loss: 0.5300 - val_accuracy: 0.7828\n",
      "Epoch 546/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5180 - accuracy: 0.7934 - val_loss: 0.5301 - val_accuracy: 0.7794\n",
      "Epoch 547/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5176 - accuracy: 0.7924 - val_loss: 0.5295 - val_accuracy: 0.7817\n",
      "Epoch 548/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5174 - accuracy: 0.7937 - val_loss: 0.5293 - val_accuracy: 0.7819\n",
      "Epoch 549/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5171 - accuracy: 0.7931 - val_loss: 0.5291 - val_accuracy: 0.7806\n",
      "Epoch 550/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5170 - accuracy: 0.7921 - val_loss: 0.5289 - val_accuracy: 0.7825\n",
      "Epoch 551/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5170 - accuracy: 0.7944 - val_loss: 0.5286 - val_accuracy: 0.7817\n",
      "Epoch 552/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5169 - accuracy: 0.7909 - val_loss: 0.5286 - val_accuracy: 0.7817\n",
      "Epoch 553/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5166 - accuracy: 0.7941 - val_loss: 0.5282 - val_accuracy: 0.7822\n",
      "Epoch 554/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5168 - accuracy: 0.7915 - val_loss: 0.5280 - val_accuracy: 0.7819\n",
      "Epoch 555/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5164 - accuracy: 0.7951 - val_loss: 0.5282 - val_accuracy: 0.7831\n",
      "Epoch 556/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5158 - accuracy: 0.7936 - val_loss: 0.5277 - val_accuracy: 0.7814\n",
      "Epoch 557/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7937 - val_loss: 0.5273 - val_accuracy: 0.7831\n",
      "Epoch 558/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5153 - accuracy: 0.7937 - val_loss: 0.5273 - val_accuracy: 0.7819\n",
      "Epoch 559/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5152 - accuracy: 0.7937 - val_loss: 0.5270 - val_accuracy: 0.7828\n",
      "Epoch 560/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5149 - accuracy: 0.7935 - val_loss: 0.5269 - val_accuracy: 0.7828\n",
      "Epoch 561/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5147 - accuracy: 0.7944 - val_loss: 0.5265 - val_accuracy: 0.7847\n",
      "Epoch 562/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5146 - accuracy: 0.7956 - val_loss: 0.5265 - val_accuracy: 0.7819\n",
      "Epoch 563/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5144 - accuracy: 0.7934 - val_loss: 0.5263 - val_accuracy: 0.7856\n",
      "Epoch 564/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5141 - accuracy: 0.7946 - val_loss: 0.5259 - val_accuracy: 0.7850\n",
      "Epoch 565/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.7948 - val_loss: 0.5258 - val_accuracy: 0.7853\n",
      "Epoch 566/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5137 - accuracy: 0.7940 - val_loss: 0.5256 - val_accuracy: 0.7858\n",
      "Epoch 567/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5135 - accuracy: 0.7951 - val_loss: 0.5253 - val_accuracy: 0.7861\n",
      "Epoch 568/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5133 - accuracy: 0.7959 - val_loss: 0.5252 - val_accuracy: 0.7858\n",
      "Epoch 569/900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7946 - val_loss: 0.5249 - val_accuracy: 0.7869\n",
      "Epoch 570/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5130 - accuracy: 0.7966 - val_loss: 0.5249 - val_accuracy: 0.7881\n",
      "Epoch 571/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5128 - accuracy: 0.7956 - val_loss: 0.5246 - val_accuracy: 0.7869\n",
      "Epoch 572/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5126 - accuracy: 0.7960 - val_loss: 0.5245 - val_accuracy: 0.7869\n",
      "Epoch 573/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5124 - accuracy: 0.7967 - val_loss: 0.5243 - val_accuracy: 0.7881\n",
      "Epoch 574/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5123 - accuracy: 0.7965 - val_loss: 0.5243 - val_accuracy: 0.7878\n",
      "Epoch 575/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5120 - accuracy: 0.7969 - val_loss: 0.5239 - val_accuracy: 0.7875\n",
      "Epoch 576/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5119 - accuracy: 0.7963 - val_loss: 0.5237 - val_accuracy: 0.7883\n",
      "Epoch 577/900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7967 - val_loss: 0.5238 - val_accuracy: 0.7892\n",
      "Epoch 578/900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.7990 - val_loss: 0.5234 - val_accuracy: 0.7889\n",
      "Epoch 579/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5114 - accuracy: 0.7969 - val_loss: 0.5232 - val_accuracy: 0.7897\n",
      "Epoch 580/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5112 - accuracy: 0.7981 - val_loss: 0.5232 - val_accuracy: 0.7889\n",
      "Epoch 581/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5109 - accuracy: 0.7977 - val_loss: 0.5228 - val_accuracy: 0.7908\n",
      "Epoch 582/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5108 - accuracy: 0.7984 - val_loss: 0.5227 - val_accuracy: 0.7919\n",
      "Epoch 583/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5108 - accuracy: 0.7983 - val_loss: 0.5227 - val_accuracy: 0.7914\n",
      "Epoch 584/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5105 - accuracy: 0.7994 - val_loss: 0.5224 - val_accuracy: 0.7914\n",
      "Epoch 585/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5104 - accuracy: 0.7972 - val_loss: 0.5223 - val_accuracy: 0.7925\n",
      "Epoch 586/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5102 - accuracy: 0.7998 - val_loss: 0.5222 - val_accuracy: 0.7925\n",
      "Epoch 587/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5100 - accuracy: 0.7986 - val_loss: 0.5219 - val_accuracy: 0.7931\n",
      "Epoch 588/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5098 - accuracy: 0.8001 - val_loss: 0.5218 - val_accuracy: 0.7933\n",
      "Epoch 589/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5097 - accuracy: 0.7989 - val_loss: 0.5217 - val_accuracy: 0.7922\n",
      "Epoch 590/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5096 - accuracy: 0.7987 - val_loss: 0.5216 - val_accuracy: 0.7931\n",
      "Epoch 591/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5096 - accuracy: 0.8008 - val_loss: 0.5213 - val_accuracy: 0.7925\n",
      "Epoch 592/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5092 - accuracy: 0.7994 - val_loss: 0.5213 - val_accuracy: 0.7933\n",
      "Epoch 593/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5093 - accuracy: 0.8004 - val_loss: 0.5212 - val_accuracy: 0.7922\n",
      "Epoch 594/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5089 - accuracy: 0.8002 - val_loss: 0.5209 - val_accuracy: 0.7944\n",
      "Epoch 595/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5087 - accuracy: 0.8013 - val_loss: 0.5210 - val_accuracy: 0.7922\n",
      "Epoch 596/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5086 - accuracy: 0.7999 - val_loss: 0.5206 - val_accuracy: 0.7939\n",
      "Epoch 597/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5084 - accuracy: 0.8018 - val_loss: 0.5205 - val_accuracy: 0.7944\n",
      "Epoch 598/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5082 - accuracy: 0.8015 - val_loss: 0.5206 - val_accuracy: 0.7925\n",
      "Epoch 599/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5083 - accuracy: 0.7988 - val_loss: 0.5205 - val_accuracy: 0.7950\n",
      "Epoch 600/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5085 - accuracy: 0.8026 - val_loss: 0.5202 - val_accuracy: 0.7947\n",
      "Epoch 601/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5080 - accuracy: 0.8007 - val_loss: 0.5201 - val_accuracy: 0.7942\n",
      "Epoch 602/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5077 - accuracy: 0.8020 - val_loss: 0.5199 - val_accuracy: 0.7944\n",
      "Epoch 603/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5076 - accuracy: 0.8003 - val_loss: 0.5198 - val_accuracy: 0.7953\n",
      "Epoch 604/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5073 - accuracy: 0.8020 - val_loss: 0.5196 - val_accuracy: 0.7944\n",
      "Epoch 605/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5071 - accuracy: 0.8021 - val_loss: 0.5195 - val_accuracy: 0.7950\n",
      "Epoch 606/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5070 - accuracy: 0.8015 - val_loss: 0.5194 - val_accuracy: 0.7953\n",
      "Epoch 607/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5068 - accuracy: 0.8020 - val_loss: 0.5192 - val_accuracy: 0.7950\n",
      "Epoch 608/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.8029 - val_loss: 0.5193 - val_accuracy: 0.7942\n",
      "Epoch 609/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5067 - accuracy: 0.8028 - val_loss: 0.5190 - val_accuracy: 0.7967\n",
      "Epoch 610/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5065 - accuracy: 0.8028 - val_loss: 0.5190 - val_accuracy: 0.7950\n",
      "Epoch 611/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5065 - accuracy: 0.8040 - val_loss: 0.5188 - val_accuracy: 0.7961\n",
      "Epoch 612/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5062 - accuracy: 0.8014 - val_loss: 0.5187 - val_accuracy: 0.7958\n",
      "Epoch 613/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5060 - accuracy: 0.8033 - val_loss: 0.5185 - val_accuracy: 0.7969\n",
      "Epoch 614/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5060 - accuracy: 0.8023 - val_loss: 0.5185 - val_accuracy: 0.7975\n",
      "Epoch 615/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5057 - accuracy: 0.8049 - val_loss: 0.5183 - val_accuracy: 0.7969\n",
      "Epoch 616/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5054 - accuracy: 0.8038 - val_loss: 0.5185 - val_accuracy: 0.7961\n",
      "Epoch 617/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5054 - accuracy: 0.8032 - val_loss: 0.5180 - val_accuracy: 0.7975\n",
      "Epoch 618/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5053 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7975\n",
      "Epoch 619/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5051 - accuracy: 0.8039 - val_loss: 0.5178 - val_accuracy: 0.7981\n",
      "Epoch 620/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5051 - accuracy: 0.8031 - val_loss: 0.5178 - val_accuracy: 0.7989\n",
      "Epoch 621/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5050 - accuracy: 0.8051 - val_loss: 0.5176 - val_accuracy: 0.7981\n",
      "Epoch 622/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5046 - accuracy: 0.8035 - val_loss: 0.5175 - val_accuracy: 0.7981\n",
      "Epoch 623/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5046 - accuracy: 0.8046 - val_loss: 0.5174 - val_accuracy: 0.7983\n",
      "Epoch 624/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5044 - accuracy: 0.8034 - val_loss: 0.5172 - val_accuracy: 0.7989\n",
      "Epoch 625/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5042 - accuracy: 0.8047 - val_loss: 0.5171 - val_accuracy: 0.7989\n",
      "Epoch 626/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5041 - accuracy: 0.8041 - val_loss: 0.5171 - val_accuracy: 0.7989\n",
      "Epoch 627/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5041 - accuracy: 0.8049 - val_loss: 0.5169 - val_accuracy: 0.8000\n",
      "Epoch 628/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5041 - accuracy: 0.8026 - val_loss: 0.5171 - val_accuracy: 0.7981\n",
      "Epoch 629/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5039 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.8006\n",
      "Epoch 630/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5037 - accuracy: 0.8035 - val_loss: 0.5166 - val_accuracy: 0.8011\n",
      "Epoch 631/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5037 - accuracy: 0.8069 - val_loss: 0.5165 - val_accuracy: 0.8000\n",
      "Epoch 632/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5037 - accuracy: 0.8040 - val_loss: 0.5164 - val_accuracy: 0.8000\n",
      "Epoch 633/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.8067 - val_loss: 0.5162 - val_accuracy: 0.8000\n",
      "Epoch 634/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5030 - accuracy: 0.8049 - val_loss: 0.5162 - val_accuracy: 0.7989\n",
      "Epoch 635/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5029 - accuracy: 0.8048 - val_loss: 0.5160 - val_accuracy: 0.8011\n",
      "Epoch 636/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5029 - accuracy: 0.8060 - val_loss: 0.5161 - val_accuracy: 0.7989\n",
      "Epoch 637/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5028 - accuracy: 0.8055 - val_loss: 0.5157 - val_accuracy: 0.8008\n",
      "Epoch 638/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.8049 - val_loss: 0.5160 - val_accuracy: 0.7981\n",
      "Epoch 639/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5028 - accuracy: 0.8065 - val_loss: 0.5156 - val_accuracy: 0.8008\n",
      "Epoch 640/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5024 - accuracy: 0.8051 - val_loss: 0.5154 - val_accuracy: 0.8008\n",
      "Epoch 641/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5022 - accuracy: 0.8066 - val_loss: 0.5153 - val_accuracy: 0.8014\n",
      "Epoch 642/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5020 - accuracy: 0.8061 - val_loss: 0.5153 - val_accuracy: 0.7994\n",
      "Epoch 643/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5020 - accuracy: 0.8048 - val_loss: 0.5151 - val_accuracy: 0.8014\n",
      "Epoch 644/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5020 - accuracy: 0.8070 - val_loss: 0.5150 - val_accuracy: 0.8003\n",
      "Epoch 645/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5017 - accuracy: 0.8047 - val_loss: 0.5153 - val_accuracy: 0.7992\n",
      "Epoch 646/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5017 - accuracy: 0.8057 - val_loss: 0.5148 - val_accuracy: 0.8014\n",
      "Epoch 647/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5018 - accuracy: 0.8056 - val_loss: 0.5148 - val_accuracy: 0.8011\n",
      "Epoch 648/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5014 - accuracy: 0.8058 - val_loss: 0.5148 - val_accuracy: 0.7997\n",
      "Epoch 649/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.8062 - val_loss: 0.5144 - val_accuracy: 0.8017\n",
      "Epoch 650/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5012 - accuracy: 0.8064 - val_loss: 0.5144 - val_accuracy: 0.8019\n",
      "Epoch 651/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5010 - accuracy: 0.8065 - val_loss: 0.5146 - val_accuracy: 0.7992\n",
      "Epoch 652/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5010 - accuracy: 0.8058 - val_loss: 0.5142 - val_accuracy: 0.8008\n",
      "Epoch 653/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5008 - accuracy: 0.8067 - val_loss: 0.5142 - val_accuracy: 0.8017\n",
      "Epoch 654/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5008 - accuracy: 0.8068 - val_loss: 0.5140 - val_accuracy: 0.8006\n",
      "Epoch 655/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5008 - accuracy: 0.8053 - val_loss: 0.5141 - val_accuracy: 0.7997\n",
      "Epoch 656/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5007 - accuracy: 0.8062 - val_loss: 0.5137 - val_accuracy: 0.8017\n",
      "Epoch 657/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5004 - accuracy: 0.8060 - val_loss: 0.5138 - val_accuracy: 0.8006\n",
      "Epoch 658/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5003 - accuracy: 0.8070 - val_loss: 0.5136 - val_accuracy: 0.8017\n",
      "Epoch 659/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5003 - accuracy: 0.8064 - val_loss: 0.5137 - val_accuracy: 0.7994\n",
      "Epoch 660/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5001 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.8019\n",
      "Epoch 661/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4999 - accuracy: 0.8078 - val_loss: 0.5133 - val_accuracy: 0.8003\n",
      "Epoch 662/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4999 - accuracy: 0.8068 - val_loss: 0.5133 - val_accuracy: 0.8003\n",
      "Epoch 663/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4999 - accuracy: 0.8079 - val_loss: 0.5132 - val_accuracy: 0.8022\n",
      "Epoch 664/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4998 - accuracy: 0.8043 - val_loss: 0.5131 - val_accuracy: 0.8022\n",
      "Epoch 665/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4999 - accuracy: 0.8081 - val_loss: 0.5130 - val_accuracy: 0.8017\n",
      "Epoch 666/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4995 - accuracy: 0.8052 - val_loss: 0.5131 - val_accuracy: 0.8017\n",
      "Epoch 667/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4996 - accuracy: 0.8072 - val_loss: 0.5128 - val_accuracy: 0.8028\n",
      "Epoch 668/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4993 - accuracy: 0.8074 - val_loss: 0.5128 - val_accuracy: 0.8031\n",
      "Epoch 669/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4993 - accuracy: 0.8071 - val_loss: 0.5127 - val_accuracy: 0.8019\n",
      "Epoch 670/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4991 - accuracy: 0.8076 - val_loss: 0.5126 - val_accuracy: 0.8014\n",
      "Epoch 671/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4992 - accuracy: 0.8072 - val_loss: 0.5123 - val_accuracy: 0.8033\n",
      "Epoch 672/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4989 - accuracy: 0.8072 - val_loss: 0.5124 - val_accuracy: 0.8017\n",
      "Epoch 673/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4987 - accuracy: 0.8071 - val_loss: 0.5121 - val_accuracy: 0.8036\n",
      "Epoch 674/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4989 - accuracy: 0.8093 - val_loss: 0.5123 - val_accuracy: 0.8017\n",
      "Epoch 675/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4987 - accuracy: 0.8058 - val_loss: 0.5120 - val_accuracy: 0.8039\n",
      "Epoch 676/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4988 - accuracy: 0.8088 - val_loss: 0.5121 - val_accuracy: 0.8019\n",
      "Epoch 677/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4985 - accuracy: 0.8061 - val_loss: 0.5119 - val_accuracy: 0.8011\n",
      "Epoch 678/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4983 - accuracy: 0.8089 - val_loss: 0.5117 - val_accuracy: 0.8031\n",
      "Epoch 679/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4981 - accuracy: 0.8087 - val_loss: 0.5116 - val_accuracy: 0.8028\n",
      "Epoch 680/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4980 - accuracy: 0.8083 - val_loss: 0.5116 - val_accuracy: 0.8011\n",
      "Epoch 681/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4980 - accuracy: 0.8083 - val_loss: 0.5115 - val_accuracy: 0.8019\n",
      "Epoch 682/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4979 - accuracy: 0.8087 - val_loss: 0.5114 - val_accuracy: 0.8036\n",
      "Epoch 683/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4979 - accuracy: 0.8089 - val_loss: 0.5114 - val_accuracy: 0.8017\n",
      "Epoch 684/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4978 - accuracy: 0.8073 - val_loss: 0.5111 - val_accuracy: 0.8036\n",
      "Epoch 685/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4976 - accuracy: 0.8090 - val_loss: 0.5110 - val_accuracy: 0.8044\n",
      "Epoch 686/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4977 - accuracy: 0.8079 - val_loss: 0.5111 - val_accuracy: 0.8014\n",
      "Epoch 687/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4975 - accuracy: 0.8087 - val_loss: 0.5108 - val_accuracy: 0.8050\n",
      "Epoch 688/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4974 - accuracy: 0.8083 - val_loss: 0.5110 - val_accuracy: 0.8028\n",
      "Epoch 689/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4973 - accuracy: 0.8078 - val_loss: 0.5108 - val_accuracy: 0.8036\n",
      "Epoch 690/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4971 - accuracy: 0.8094 - val_loss: 0.5108 - val_accuracy: 0.8031\n",
      "Epoch 691/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4972 - accuracy: 0.8070 - val_loss: 0.5105 - val_accuracy: 0.8036\n",
      "Epoch 692/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4972 - accuracy: 0.8095 - val_loss: 0.5105 - val_accuracy: 0.8031\n",
      "Epoch 693/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4970 - accuracy: 0.8082 - val_loss: 0.5103 - val_accuracy: 0.8042\n",
      "Epoch 694/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4969 - accuracy: 0.8096 - val_loss: 0.5104 - val_accuracy: 0.8019\n",
      "Epoch 695/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4967 - accuracy: 0.8080 - val_loss: 0.5102 - val_accuracy: 0.8039\n",
      "Epoch 696/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4966 - accuracy: 0.8090 - val_loss: 0.5101 - val_accuracy: 0.8042\n",
      "Epoch 697/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4967 - accuracy: 0.8093 - val_loss: 0.5103 - val_accuracy: 0.8033\n",
      "Epoch 698/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4967 - accuracy: 0.8081 - val_loss: 0.5101 - val_accuracy: 0.8031\n",
      "Epoch 699/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4965 - accuracy: 0.8096 - val_loss: 0.5098 - val_accuracy: 0.8053\n",
      "Epoch 700/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.8096 - val_loss: 0.5098 - val_accuracy: 0.8039\n",
      "Epoch 701/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4965 - accuracy: 0.8078 - val_loss: 0.5097 - val_accuracy: 0.8019\n",
      "Epoch 702/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4962 - accuracy: 0.8099 - val_loss: 0.5096 - val_accuracy: 0.8047\n",
      "Epoch 703/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4965 - accuracy: 0.8080 - val_loss: 0.5097 - val_accuracy: 0.8033\n",
      "Epoch 704/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4965 - accuracy: 0.8099 - val_loss: 0.5095 - val_accuracy: 0.8039\n",
      "Epoch 705/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4964 - accuracy: 0.8078 - val_loss: 0.5096 - val_accuracy: 0.8033\n",
      "Epoch 706/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4960 - accuracy: 0.8090 - val_loss: 0.5094 - val_accuracy: 0.8036\n",
      "Epoch 707/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4961 - accuracy: 0.8077 - val_loss: 0.5094 - val_accuracy: 0.8028\n",
      "Epoch 708/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4958 - accuracy: 0.8097 - val_loss: 0.5091 - val_accuracy: 0.8044\n",
      "Epoch 709/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4956 - accuracy: 0.8091 - val_loss: 0.5092 - val_accuracy: 0.8033\n",
      "Epoch 710/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4957 - accuracy: 0.8092 - val_loss: 0.5091 - val_accuracy: 0.8017\n",
      "Epoch 711/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4955 - accuracy: 0.8093 - val_loss: 0.5090 - val_accuracy: 0.8031\n",
      "Epoch 712/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4955 - accuracy: 0.8094 - val_loss: 0.5088 - val_accuracy: 0.8039\n",
      "Epoch 713/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4953 - accuracy: 0.8086 - val_loss: 0.5089 - val_accuracy: 0.8031\n",
      "Epoch 714/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4953 - accuracy: 0.8092 - val_loss: 0.5086 - val_accuracy: 0.8036\n",
      "Epoch 715/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4950 - accuracy: 0.8090 - val_loss: 0.5088 - val_accuracy: 0.8025\n",
      "Epoch 716/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4954 - accuracy: 0.8076 - val_loss: 0.5085 - val_accuracy: 0.8033\n",
      "Epoch 717/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4952 - accuracy: 0.8094 - val_loss: 0.5086 - val_accuracy: 0.8031\n",
      "Epoch 718/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4951 - accuracy: 0.8083 - val_loss: 0.5083 - val_accuracy: 0.8044\n",
      "Epoch 719/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4951 - accuracy: 0.8092 - val_loss: 0.5083 - val_accuracy: 0.8042\n",
      "Epoch 720/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4951 - accuracy: 0.8078 - val_loss: 0.5084 - val_accuracy: 0.8017\n",
      "Epoch 721/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4949 - accuracy: 0.8090 - val_loss: 0.5081 - val_accuracy: 0.8053\n",
      "Epoch 722/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4945 - accuracy: 0.8088 - val_loss: 0.5083 - val_accuracy: 0.8028\n",
      "Epoch 723/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4946 - accuracy: 0.8079 - val_loss: 0.5081 - val_accuracy: 0.8028\n",
      "Epoch 724/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4946 - accuracy: 0.8082 - val_loss: 0.5082 - val_accuracy: 0.8025\n",
      "Epoch 725/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4944 - accuracy: 0.8090 - val_loss: 0.5079 - val_accuracy: 0.8053\n",
      "Epoch 726/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4944 - accuracy: 0.8092 - val_loss: 0.5080 - val_accuracy: 0.8028\n",
      "Epoch 727/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4942 - accuracy: 0.8085 - val_loss: 0.5077 - val_accuracy: 0.8044\n",
      "Epoch 728/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4942 - accuracy: 0.8094 - val_loss: 0.5076 - val_accuracy: 0.8044\n",
      "Epoch 729/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.8084 - val_loss: 0.5077 - val_accuracy: 0.8019\n",
      "Epoch 730/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4940 - accuracy: 0.8088 - val_loss: 0.5075 - val_accuracy: 0.8044\n",
      "Epoch 731/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4939 - accuracy: 0.8094 - val_loss: 0.5074 - val_accuracy: 0.8036\n",
      "Epoch 732/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.8082 - val_loss: 0.5075 - val_accuracy: 0.8031\n",
      "Epoch 733/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4940 - accuracy: 0.8088 - val_loss: 0.5075 - val_accuracy: 0.8028\n",
      "Epoch 734/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4942 - accuracy: 0.8078 - val_loss: 0.5076 - val_accuracy: 0.8022\n",
      "Epoch 735/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4936 - accuracy: 0.8088 - val_loss: 0.5074 - val_accuracy: 0.8028\n",
      "Epoch 736/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4939 - accuracy: 0.8083 - val_loss: 0.5075 - val_accuracy: 0.8025\n",
      "Epoch 737/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4936 - accuracy: 0.8085 - val_loss: 0.5071 - val_accuracy: 0.8061\n",
      "Epoch 738/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4936 - accuracy: 0.8092 - val_loss: 0.5073 - val_accuracy: 0.8025\n",
      "Epoch 739/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4935 - accuracy: 0.8088 - val_loss: 0.5069 - val_accuracy: 0.8033\n",
      "Epoch 740/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4934 - accuracy: 0.8096 - val_loss: 0.5068 - val_accuracy: 0.8044\n",
      "Epoch 741/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4933 - accuracy: 0.8088 - val_loss: 0.5068 - val_accuracy: 0.8031\n",
      "Epoch 742/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4932 - accuracy: 0.8082 - val_loss: 0.5068 - val_accuracy: 0.8033\n",
      "Epoch 743/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4932 - accuracy: 0.8081 - val_loss: 0.5066 - val_accuracy: 0.8044\n",
      "Epoch 744/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4931 - accuracy: 0.8097 - val_loss: 0.5066 - val_accuracy: 0.8033\n",
      "Epoch 745/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4931 - accuracy: 0.8093 - val_loss: 0.5065 - val_accuracy: 0.8031\n",
      "Epoch 746/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4929 - accuracy: 0.8088 - val_loss: 0.5066 - val_accuracy: 0.8025\n",
      "Epoch 747/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4930 - accuracy: 0.8085 - val_loss: 0.5063 - val_accuracy: 0.8042\n",
      "Epoch 748/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4928 - accuracy: 0.8097 - val_loss: 0.5063 - val_accuracy: 0.8050\n",
      "Epoch 749/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4928 - accuracy: 0.8087 - val_loss: 0.5063 - val_accuracy: 0.8039\n",
      "Epoch 750/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4927 - accuracy: 0.8092 - val_loss: 0.5063 - val_accuracy: 0.8028\n",
      "Epoch 751/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4926 - accuracy: 0.8093 - val_loss: 0.5061 - val_accuracy: 0.8047\n",
      "Epoch 752/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4926 - accuracy: 0.8095 - val_loss: 0.5062 - val_accuracy: 0.8031\n",
      "Epoch 753/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4925 - accuracy: 0.8091 - val_loss: 0.5060 - val_accuracy: 0.8036\n",
      "Epoch 754/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.8085 - val_loss: 0.5059 - val_accuracy: 0.8042\n",
      "Epoch 755/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.8096 - val_loss: 0.5059 - val_accuracy: 0.8031\n",
      "Epoch 756/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4925 - accuracy: 0.8099 - val_loss: 0.5057 - val_accuracy: 0.8036\n",
      "Epoch 757/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4921 - accuracy: 0.8097 - val_loss: 0.5058 - val_accuracy: 0.8033\n",
      "Epoch 758/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.8087 - val_loss: 0.5057 - val_accuracy: 0.8036\n",
      "Epoch 759/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4919 - accuracy: 0.8099 - val_loss: 0.5057 - val_accuracy: 0.8044\n",
      "Epoch 760/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4922 - accuracy: 0.8103 - val_loss: 0.5055 - val_accuracy: 0.8050\n",
      "Epoch 761/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.8090 - val_loss: 0.5057 - val_accuracy: 0.8031\n",
      "Epoch 762/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4919 - accuracy: 0.8097 - val_loss: 0.5053 - val_accuracy: 0.8056\n",
      "Epoch 763/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.8103 - val_loss: 0.5053 - val_accuracy: 0.8042\n",
      "Epoch 764/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.8090 - val_loss: 0.5053 - val_accuracy: 0.8039\n",
      "Epoch 765/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.8099 - val_loss: 0.5051 - val_accuracy: 0.8036\n",
      "Epoch 766/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4918 - accuracy: 0.8094 - val_loss: 0.5051 - val_accuracy: 0.8053\n",
      "Epoch 767/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4917 - accuracy: 0.8099 - val_loss: 0.5050 - val_accuracy: 0.8036\n",
      "Epoch 768/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4916 - accuracy: 0.8099 - val_loss: 0.5050 - val_accuracy: 0.8017\n",
      "Epoch 769/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4914 - accuracy: 0.8097 - val_loss: 0.5049 - val_accuracy: 0.8061\n",
      "Epoch 770/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4917 - accuracy: 0.8103 - val_loss: 0.5050 - val_accuracy: 0.8028\n",
      "Epoch 771/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4916 - accuracy: 0.8098 - val_loss: 0.5051 - val_accuracy: 0.8053\n",
      "Epoch 772/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.8101 - val_loss: 0.5050 - val_accuracy: 0.8025\n",
      "Epoch 773/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4914 - accuracy: 0.8095 - val_loss: 0.5046 - val_accuracy: 0.8036\n",
      "Epoch 774/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4912 - accuracy: 0.8097 - val_loss: 0.5047 - val_accuracy: 0.8033\n",
      "Epoch 775/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.8093 - val_loss: 0.5045 - val_accuracy: 0.8058\n",
      "Epoch 776/900\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4911 - accuracy: 0.8099 - val_loss: 0.5047 - val_accuracy: 0.8028\n",
      "Epoch 777/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4912 - accuracy: 0.8095 - val_loss: 0.5045 - val_accuracy: 0.8031\n",
      "Epoch 778/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.8094 - val_loss: 0.5043 - val_accuracy: 0.8042\n",
      "Epoch 779/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4909 - accuracy: 0.8103 - val_loss: 0.5043 - val_accuracy: 0.8050\n",
      "Epoch 780/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4909 - accuracy: 0.8101 - val_loss: 0.5042 - val_accuracy: 0.8033\n",
      "Epoch 781/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4909 - accuracy: 0.8089 - val_loss: 0.5042 - val_accuracy: 0.8053\n",
      "Epoch 782/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.8094 - val_loss: 0.5042 - val_accuracy: 0.8036\n",
      "Epoch 783/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4906 - accuracy: 0.8094 - val_loss: 0.5041 - val_accuracy: 0.8042\n",
      "Epoch 784/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4908 - accuracy: 0.8105 - val_loss: 0.5040 - val_accuracy: 0.8042\n",
      "Epoch 785/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4908 - accuracy: 0.8101 - val_loss: 0.5041 - val_accuracy: 0.8039\n",
      "Epoch 786/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4906 - accuracy: 0.8103 - val_loss: 0.5039 - val_accuracy: 0.8033\n",
      "Epoch 787/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4904 - accuracy: 0.8099 - val_loss: 0.5040 - val_accuracy: 0.8050\n",
      "Epoch 788/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.8097 - val_loss: 0.5038 - val_accuracy: 0.8042\n",
      "Epoch 789/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.8103 - val_loss: 0.5037 - val_accuracy: 0.8047\n",
      "Epoch 790/900\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4904 - accuracy: 0.8101 - val_loss: 0.5037 - val_accuracy: 0.8036\n",
      "Epoch 791/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4902 - accuracy: 0.8100 - val_loss: 0.5036 - val_accuracy: 0.8050\n",
      "Epoch 792/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4903 - accuracy: 0.8092 - val_loss: 0.5037 - val_accuracy: 0.8025\n",
      "Epoch 793/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4901 - accuracy: 0.8099 - val_loss: 0.5034 - val_accuracy: 0.8050\n",
      "Epoch 794/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4903 - accuracy: 0.8096 - val_loss: 0.5037 - val_accuracy: 0.8050\n",
      "Epoch 795/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4904 - accuracy: 0.8085 - val_loss: 0.5034 - val_accuracy: 0.8036\n",
      "Epoch 796/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.8103 - val_loss: 0.5035 - val_accuracy: 0.8072\n",
      "Epoch 797/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4901 - accuracy: 0.8092 - val_loss: 0.5034 - val_accuracy: 0.8033\n",
      "Epoch 798/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4900 - accuracy: 0.8103 - val_loss: 0.5031 - val_accuracy: 0.8053\n",
      "Epoch 799/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.8101 - val_loss: 0.5032 - val_accuracy: 0.8042\n",
      "Epoch 800/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4898 - accuracy: 0.8094 - val_loss: 0.5032 - val_accuracy: 0.8042\n",
      "Epoch 801/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4897 - accuracy: 0.8104 - val_loss: 0.5030 - val_accuracy: 0.8050\n",
      "Epoch 802/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4897 - accuracy: 0.8111 - val_loss: 0.5029 - val_accuracy: 0.8058\n",
      "Epoch 803/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.8100 - val_loss: 0.5032 - val_accuracy: 0.8058\n",
      "Epoch 804/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4897 - accuracy: 0.8091 - val_loss: 0.5029 - val_accuracy: 0.8044\n",
      "Epoch 805/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.8115 - val_loss: 0.5028 - val_accuracy: 0.8036\n",
      "Epoch 806/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.8097 - val_loss: 0.5030 - val_accuracy: 0.8058\n",
      "Epoch 807/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.8103 - val_loss: 0.5026 - val_accuracy: 0.8042\n",
      "Epoch 808/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4895 - accuracy: 0.8099 - val_loss: 0.5027 - val_accuracy: 0.8039\n",
      "Epoch 809/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4892 - accuracy: 0.8104 - val_loss: 0.5026 - val_accuracy: 0.8058\n",
      "Epoch 810/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4893 - accuracy: 0.8102 - val_loss: 0.5024 - val_accuracy: 0.8056\n",
      "Epoch 811/900\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.8107 - val_loss: 0.5024 - val_accuracy: 0.8061\n",
      "Epoch 812/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.8099 - val_loss: 0.5027 - val_accuracy: 0.8036\n",
      "Epoch 813/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.8081 - val_loss: 0.5023 - val_accuracy: 0.8047\n",
      "Epoch 814/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4894 - accuracy: 0.8104 - val_loss: 0.5025 - val_accuracy: 0.8050\n",
      "Epoch 815/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4891 - accuracy: 0.8098 - val_loss: 0.5025 - val_accuracy: 0.8017\n",
      "Epoch 816/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.8108 - val_loss: 0.5021 - val_accuracy: 0.8056\n",
      "Epoch 817/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4888 - accuracy: 0.8099 - val_loss: 0.5022 - val_accuracy: 0.8047\n",
      "Epoch 818/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.8100 - val_loss: 0.5020 - val_accuracy: 0.8064\n",
      "Epoch 819/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4888 - accuracy: 0.8102 - val_loss: 0.5020 - val_accuracy: 0.8061\n",
      "Epoch 820/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.8103 - val_loss: 0.5019 - val_accuracy: 0.8061\n",
      "Epoch 821/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.8112 - val_loss: 0.5019 - val_accuracy: 0.8039\n",
      "Epoch 822/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4885 - accuracy: 0.8106 - val_loss: 0.5020 - val_accuracy: 0.8056\n",
      "Epoch 823/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4887 - accuracy: 0.8103 - val_loss: 0.5018 - val_accuracy: 0.8058\n",
      "Epoch 824/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4885 - accuracy: 0.8105 - val_loss: 0.5017 - val_accuracy: 0.8047\n",
      "Epoch 825/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4884 - accuracy: 0.8106 - val_loss: 0.5017 - val_accuracy: 0.8050\n",
      "Epoch 826/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4885 - accuracy: 0.8098 - val_loss: 0.5017 - val_accuracy: 0.8047\n",
      "Epoch 827/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4886 - accuracy: 0.8106 - val_loss: 0.5015 - val_accuracy: 0.8053\n",
      "Epoch 828/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4884 - accuracy: 0.8097 - val_loss: 0.5018 - val_accuracy: 0.8047\n",
      "Epoch 829/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4884 - accuracy: 0.8098 - val_loss: 0.5015 - val_accuracy: 0.8036\n",
      "Epoch 830/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4882 - accuracy: 0.8107 - val_loss: 0.5015 - val_accuracy: 0.8058\n",
      "Epoch 831/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.8103 - val_loss: 0.5013 - val_accuracy: 0.8047\n",
      "Epoch 832/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.8107 - val_loss: 0.5012 - val_accuracy: 0.8058\n",
      "Epoch 833/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.8106 - val_loss: 0.5013 - val_accuracy: 0.8053\n",
      "Epoch 834/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4880 - accuracy: 0.8102 - val_loss: 0.5012 - val_accuracy: 0.8050\n",
      "Epoch 835/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4881 - accuracy: 0.8109 - val_loss: 0.5010 - val_accuracy: 0.8064\n",
      "Epoch 836/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4879 - accuracy: 0.8101 - val_loss: 0.5012 - val_accuracy: 0.8053\n",
      "Epoch 837/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4880 - accuracy: 0.8106 - val_loss: 0.5009 - val_accuracy: 0.8064\n",
      "Epoch 838/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4882 - accuracy: 0.8103 - val_loss: 0.5009 - val_accuracy: 0.8064\n",
      "Epoch 839/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4880 - accuracy: 0.8102 - val_loss: 0.5010 - val_accuracy: 0.8058\n",
      "Epoch 840/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4879 - accuracy: 0.8108 - val_loss: 0.5009 - val_accuracy: 0.8039\n",
      "Epoch 841/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.8108 - val_loss: 0.5008 - val_accuracy: 0.8064\n",
      "Epoch 842/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.8100 - val_loss: 0.5009 - val_accuracy: 0.8033\n",
      "Epoch 843/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.8105 - val_loss: 0.5006 - val_accuracy: 0.8058\n",
      "Epoch 844/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4875 - accuracy: 0.8108 - val_loss: 0.5006 - val_accuracy: 0.8061\n",
      "Epoch 845/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4875 - accuracy: 0.8108 - val_loss: 0.5005 - val_accuracy: 0.8064\n",
      "Epoch 846/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4874 - accuracy: 0.8107 - val_loss: 0.5005 - val_accuracy: 0.8069\n",
      "Epoch 847/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4874 - accuracy: 0.8099 - val_loss: 0.5004 - val_accuracy: 0.8061\n",
      "Epoch 848/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4874 - accuracy: 0.8102 - val_loss: 0.5003 - val_accuracy: 0.8058\n",
      "Epoch 849/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.8103 - val_loss: 0.5002 - val_accuracy: 0.8053\n",
      "Epoch 850/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4872 - accuracy: 0.8110 - val_loss: 0.5002 - val_accuracy: 0.8053\n",
      "Epoch 851/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.8101 - val_loss: 0.5003 - val_accuracy: 0.8050\n",
      "Epoch 852/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4874 - accuracy: 0.8104 - val_loss: 0.5000 - val_accuracy: 0.8058\n",
      "Epoch 853/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4871 - accuracy: 0.8105 - val_loss: 0.5004 - val_accuracy: 0.8053\n",
      "Epoch 854/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4873 - accuracy: 0.8105 - val_loss: 0.4999 - val_accuracy: 0.8061\n",
      "Epoch 855/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.8111 - val_loss: 0.5002 - val_accuracy: 0.8044\n",
      "Epoch 856/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4870 - accuracy: 0.8094 - val_loss: 0.5000 - val_accuracy: 0.8061\n",
      "Epoch 857/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4869 - accuracy: 0.8112 - val_loss: 0.4998 - val_accuracy: 0.8058\n",
      "Epoch 858/900\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4868 - accuracy: 0.8109 - val_loss: 0.4998 - val_accuracy: 0.8061\n",
      "Epoch 859/900\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4869 - accuracy: 0.8102 - val_loss: 0.4998 - val_accuracy: 0.8064\n",
      "Epoch 860/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4869 - accuracy: 0.8103 - val_loss: 0.4996 - val_accuracy: 0.8061\n",
      "Epoch 861/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.8108 - val_loss: 0.4997 - val_accuracy: 0.8058\n",
      "Epoch 862/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.8110 - val_loss: 0.4995 - val_accuracy: 0.8061\n",
      "Epoch 863/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4866 - accuracy: 0.8106 - val_loss: 0.4995 - val_accuracy: 0.8069\n",
      "Epoch 864/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4866 - accuracy: 0.8097 - val_loss: 0.4994 - val_accuracy: 0.8053\n",
      "Epoch 865/900\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4866 - accuracy: 0.8110 - val_loss: 0.4992 - val_accuracy: 0.8058\n",
      "Epoch 866/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4865 - accuracy: 0.8119 - val_loss: 0.4995 - val_accuracy: 0.8042\n",
      "Epoch 867/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4863 - accuracy: 0.8102 - val_loss: 0.4992 - val_accuracy: 0.8058\n",
      "Epoch 868/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4863 - accuracy: 0.8112 - val_loss: 0.4991 - val_accuracy: 0.8058\n",
      "Epoch 869/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4866 - accuracy: 0.8110 - val_loss: 0.4995 - val_accuracy: 0.8031\n",
      "Epoch 870/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4862 - accuracy: 0.8103 - val_loss: 0.4990 - val_accuracy: 0.8075\n",
      "Epoch 871/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4865 - accuracy: 0.8103 - val_loss: 0.4992 - val_accuracy: 0.8047\n",
      "Epoch 872/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4861 - accuracy: 0.8112 - val_loss: 0.4988 - val_accuracy: 0.8056\n",
      "Epoch 873/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4862 - accuracy: 0.8112 - val_loss: 0.4989 - val_accuracy: 0.8061\n",
      "Epoch 874/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4861 - accuracy: 0.8099 - val_loss: 0.4990 - val_accuracy: 0.8044\n",
      "Epoch 875/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4859 - accuracy: 0.8106 - val_loss: 0.4987 - val_accuracy: 0.8064\n",
      "Epoch 876/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4860 - accuracy: 0.8114 - val_loss: 0.4988 - val_accuracy: 0.8050\n",
      "Epoch 877/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4859 - accuracy: 0.8093 - val_loss: 0.4986 - val_accuracy: 0.8061\n",
      "Epoch 878/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4859 - accuracy: 0.8113 - val_loss: 0.4984 - val_accuracy: 0.8072\n",
      "Epoch 879/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4857 - accuracy: 0.8106 - val_loss: 0.4987 - val_accuracy: 0.8039\n",
      "Epoch 880/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4857 - accuracy: 0.8108 - val_loss: 0.4983 - val_accuracy: 0.8053\n",
      "Epoch 881/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4856 - accuracy: 0.8114 - val_loss: 0.4984 - val_accuracy: 0.8058\n",
      "Epoch 882/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.8095 - val_loss: 0.4984 - val_accuracy: 0.8069\n",
      "Epoch 883/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4855 - accuracy: 0.8107 - val_loss: 0.4981 - val_accuracy: 0.8067\n",
      "Epoch 884/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4854 - accuracy: 0.8108 - val_loss: 0.4982 - val_accuracy: 0.8061\n",
      "Epoch 885/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4854 - accuracy: 0.8111 - val_loss: 0.4981 - val_accuracy: 0.8061\n",
      "Epoch 886/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4856 - accuracy: 0.8098 - val_loss: 0.4981 - val_accuracy: 0.8061\n",
      "Epoch 887/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4855 - accuracy: 0.8106 - val_loss: 0.4981 - val_accuracy: 0.8050\n",
      "Epoch 888/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4853 - accuracy: 0.8104 - val_loss: 0.4979 - val_accuracy: 0.8064\n",
      "Epoch 889/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4852 - accuracy: 0.8109 - val_loss: 0.4979 - val_accuracy: 0.8053\n",
      "Epoch 890/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.8103 - val_loss: 0.4978 - val_accuracy: 0.8058\n",
      "Epoch 891/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4851 - accuracy: 0.8110 - val_loss: 0.4977 - val_accuracy: 0.8047\n",
      "Epoch 892/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4850 - accuracy: 0.8109 - val_loss: 0.4977 - val_accuracy: 0.8067\n",
      "Epoch 893/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.8109 - val_loss: 0.4980 - val_accuracy: 0.8025\n",
      "Epoch 894/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.8103 - val_loss: 0.4975 - val_accuracy: 0.8069\n",
      "Epoch 895/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4850 - accuracy: 0.8103 - val_loss: 0.4978 - val_accuracy: 0.8031\n",
      "Epoch 896/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.8088 - val_loss: 0.4974 - val_accuracy: 0.8064\n",
      "Epoch 897/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4850 - accuracy: 0.8115 - val_loss: 0.4973 - val_accuracy: 0.8064\n",
      "Epoch 898/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.8087 - val_loss: 0.4975 - val_accuracy: 0.8050\n",
      "Epoch 899/900\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.8108 - val_loss: 0.4972 - val_accuracy: 0.8058\n",
      "Epoch 900/900\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4847 - accuracy: 0.8099 - val_loss: 0.4975 - val_accuracy: 0.8039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prepare_data',\n",
       "                 PrepareData(drop_colums=['NOME', 'MATRICULA', 'FALTAS',\n",
       "                                          'INGLES'],\n",
       "                             merge_comlumns_to_name=['H_AULA_PRES',\n",
       "                                                     'TAREFAS_ONLINE',\n",
       "                                                     'ATIVIDADES'],\n",
       "                             proporcional_in_columns=['NOTA_DE', 'NOTA_GO',\n",
       "                                                      'NOTA_MF', 'NOTA_EM'])),\n",
       "                ('model',\n",
       "                 DenseModel(activation=<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fa3c8aa3908>,\n",
       "                            batch_size=900, epochs=2500, input_s=9,\n",
       "                            num_classes=5,\n",
       "                            prepare_data=PrepareData(drop_colums=['NOME',\n",
       "                                                                  'MATRICULA',\n",
       "                                                                  'FALTAS',\n",
       "                                                                  'INGLES'],\n",
       "                                                     merge_comlumns_to_name=['H_AULA_PRES',\n",
       "                                                                             'TAREFAS_ONLINE',\n",
       "                                                                             'ATIVIDADES'],\n",
       "                                                     proporcional_in_columns=['NOTA_DE',\n",
       "                                                                              'NOTA_GO',\n",
       "                                                                              'NOTA_MF',\n",
       "                                                                              'NOTA_EM'])))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respostas do modelo e testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXCELENTE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXCELENTE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'EXCELENTE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXCELENTE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'EXATAS',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " 'HUMANAS',\n",
       " 'DIFICULDADE',\n",
       " 'DIFICULDADE',\n",
       " 'EXATAS',\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.8025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5071431398391724, 0.8025000095367432]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAs4ElEQVR4nO3deZwcdZ3/8denu2e6576TSWZCDki45AhEENA1gLiACOgCGi9YEBZ2ldXdFcU91N1112s9WBWvn7JeZFkPRBFQkUNFkaCAkHCTwOTOJHPP9Pn5/VGVZBImF5memky9n49HPbq6qrr700WT93zrW/Utc3dERCS+ElEXICIi0VIQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzCkIRPbAzOaYmZtZai+2vcTMfj0RdYmMFwWBTClmttLMcmbWutPyP4b/mM+JqLR9ChSRiaQgkKnoOWDJ1idmdhRQHV05IpObgkCmom8B7xj1/GLgm6M3MLMGM/ummW00s1Vm9k9mlgjXJc3sU2a2ycyeBV43xmv/n5mtNbPVZvbvZpbcn4LNbKaZ3WJmm83saTO7fNS6E8xsmZn1mdl6M/t0uDxjZt82s24z6zGzB8xs+v7UIfGkIJCp6HdAvZkdHv4D/Wbg2ztt899AAzAPeDVBcPxluO5y4BxgIbAIuGCn194AFIBDwm1eC7xzP2teCnQBM8PP+w8zOy1c9zngc+5eDxwM3BQuvzj8DrOAFuBKYHg/65AYUhDIVLW1VXAGsAJYvXXFqHC41t373X0l8F/A28NNLgI+6+4vuPtm4D9HvXY6cDbwHncfdPcNwGfC93tJzGwWcArwfncfcfeHgK+xvVWTBw4xs1Z3H3D3341a3gIc4u5Fd3/Q3fteah0SXwoCmaq+BbwFuISdDgsBrUAFsGrUslVARzg/E3hhp3VbzQ5fuzY8HNMDfBmYth+1zgQ2u3v/Luq5DFgAPB4e/jknXP4t4A5gqZmtMbNPmFnFftQhMaUgkCnJ3VcRdBqfDfxgp9WbCP6anj1q2UFsbzWsJTjcMnrdVi8AWaDV3RvDqd7dj9yPctcAzWZWN1Y97v6Uuy8hCJuPA98zsxp3z7v7R9z9COBkgsNZ70BkHykIZCq7DDjN3QdHL3T3IsFx9o+aWZ2ZzQb+ju39CDcBV5tZp5k1AR8Y9dq1wM+A/zKzejNLmNnBZvbqfagrHXb0ZswsQ/AP/n3Af4bLjg5r/zaAmb3NzNrcvQT0hO9RMrNTzeyo8FBXH0G4lfahDhFAQSBTmLs/4+7LdrH63cAg8Czwa+C7wNfDdV8lOOTyMPAHXtyieAdQCSwHtgDfA2bsQ2kDBJ26W6fTCE53nUPQOvgh8CF3/0W4/ZnAY2Y2QNBx/GZ3Hwbaw8/uI+gHuYfgcJHIPjHdmEZEJN7UIhARiTkFgYhIzCkIRERiTkEgIhJzB9woiK2trT5nzpyoyxAROaA8+OCDm9y9bax1B1wQzJkzh2XLdnVGoIiIjMXMVu1qnQ4NiYjEnIJARCTmFAQiIjF3wPURiIjsq3w+T1dXFyMjI1GXUnaZTIbOzk4qKvZ+IFoFgYhMeV1dXdTV1TFnzhzMLOpyysbd6e7upquri7lz5+7163RoSESmvJGREVpaWqZ0CACYGS0tLfvc8lEQiEgsTPUQ2OqlfM/YBMHj6/r4xO2P0zuUj7oUEZFJJTZBsHb18zx17//y/IbuqEsRkZjp7u7m2GOP5dhjj6W9vZ2Ojo5tz3O53G5fu2zZMq6++uqy1hebzuKDBx/iq5Wf5terF8Oc9qjLEZEYaWlp4aGHHgLgwx/+MLW1tfzDP/zDtvWFQoFUaux/jhctWsSiRYvKWl9sWgQNMw4GYHjDcxFXIiICl1xyCVdeeSUnnngi11xzDb///e856aSTWLhwISeffDJPPPEEAHfffTfnnHMOEITIpZdeyuLFi5k3bx7XXXfduNQSmxZBffs8AEpbdjnchojEwEd+/BjL1/SN63seMbOeD73+yH1+XVdXF/fddx/JZJK+vj5+9atfkUql+MUvfsEHP/hBvv/977/oNY8//jh33XUX/f39HHrooVx11VX7dM3AWGITBFY7jSyVJPu6oi5FRASACy+8kGQyCUBvby8XX3wxTz31FGZGPj/2iS2ve93rSKfTpNNppk2bxvr16+ns7NyvOmITBJjRnZpG9fDqqCsRkQi9lL/cy6Wmpmbb/D//8z9z6qmn8sMf/pCVK1eyePHiMV+TTqe3zSeTSQqFwn7XEZs+AoC+zEwac+uiLkNE5EV6e3vp6OgA4IYbbpjQz45VEORqOphe2kC+WIq6FBGRHVxzzTVce+21LFy4cFz+yt8X5u4T+oH7a9GiRf5Sb0zz8Hf/hWOe/BxdVz1D5/TWca5MRCarFStWcPjhh0ddxoQZ6/ua2YPuPuZ5qLFqEVS2zgZg8+qnI65ERGTyKFsQmNnXzWyDmT26m20Wm9lDZvaYmd1Trlq2aphxCAB9654p90eJiBwwytkiuAE4c1crzawR+CJwrrsfCVxYxloAaJm1AID8xmfL/VEiIgeMsgWBu98LbN7NJm8BfuDuz4fbbyhXLVulG9oZJk2i9/lyf5SIyAEjyj6CBUCTmd1tZg+a2Tt2taGZXWFmy8xs2caNG1/6J5qxMdVO9eALL/09RESmmCiDIAUcD7wO+HPgn81swVgbuvtX3H2Ruy9qa2vbrw/ty3TQlFuzX+8hIjKVRBkEXcAd7j7o7puAe4Fjyv2hubqDaC+tJ5cvlvujREQAOPXUU7njjjt2WPbZz36Wq666asztFy9ezEs9Tf6liDIIfgS80sxSZlYNnAisKPeHWtNsam2E9es11ISITIwlS5awdOnSHZYtXbqUJUuWRFTRjsp5+uiNwG+BQ82sy8wuM7MrzexKAHdfAdwOPAL8Hviau+/yVNPxkpkWDEfd/cJT5f4oEREALrjgAm699dZtN6FZuXIla9as4cYbb2TRokUceeSRfOhDH4qsvrINOufue4w6d/8k8Mly1TCWxo6gG2Jo/dPA6RP50SIyGdz2AVj3p/F9z/aj4KyP7XJ1c3MzJ5xwArfddhvnnXceS5cu5aKLLuKDH/wgzc3NFItFTj/9dB555BGOPvro8a1tL8TqymKAts7gorJCt25QIyITZ/Thoa2HhW666SaOO+44Fi5cyGOPPcby5csjqS0+w1CHUlV1dNNIqk/XEojE0m7+ci+n8847j/e+97384Q9/YGhoiObmZj71qU/xwAMP0NTUxCWXXMLIyEgktcWuRQDQXTGD2iHdoEZEJk5tbS2nnnoql156KUuWLKGvr4+amhoaGhpYv349t912W2S1xa5FADBQ3cH03keiLkNEYmbJkiW84Q1vYOnSpRx22GEsXLiQww47jFmzZnHKKadEVlcsg6BU10Frz92M5PJkKvfvXp8iInvr/PPPZ/TQ/7u6Ac3dd989MQWFYnloqKKpg7QVWLtG1xKIiMQyCKpaZgGwZb3OHBIRiWUQ1E0LblAztEkdxiJxcaDdjfGleinfM5ZB0NQ+B4BCj4JAJA4ymQzd3d1TPgzcne7ubjKZzD69LpadxZnGdgoksD6NQioSB52dnXR1dbFfw9gfIDKZDJ2dnfv0mlgGAYkkm62ZisF1UVciIhOgoqKCuXPnRl3GpBXLQ0MAvRXTqMmuj7oMEZHIxTYIhjLTachP/WaiiMiexDYI8jXTafNuisVS1KWIiEQqtkFAfQc1lqV786aoKxERiVRsg6CyKehV37JuZbSFiIhELLZBUN0aXF08sGFVxJWIiEQrtkHQOD24uji7ReMNiUi8xTYImtqDIPAeBYGIxFtsgyBZkWYzDSQH10ZdiohIpGIbBACbU21UDevqYhGJt1gHwUDlNGpzuqhMROIt1kGQrW6npaTrCEQk3mIdBF47g0YGGBkaiLoUEZHIlC0IzOzrZrbBzB7dw3YvN7OCmV1Qrlp2JdHYAcCmNSsn+qNFRCaNcrYIbgDO3N0GZpYEPg78rIx17FJVS3B1cZ8uKhORGCtbELj7vcDmPWz2buD7wIZy1bE79a1Bi2Bws04hFZH4iqyPwMw6gDcA1+/FtleY2TIzWzaedxhqnh60CPK9OoVUROIrys7izwLvd/c9jgPt7l9x90XuvqitrW3cCqhtbKPgCUr9kTRIREQmhShvVbkIWGpmAK3A2WZWcPebJ6oASyTpSTSQHNa1BCISX5EFgbtvu4Gomd0A/GQiQ2CrvmQT6Wz3RH+siMikUbYgMLMbgcVAq5l1AR8CKgDc/Uvl+tx9NVTRQk1uT33aIiJTV9mCwN2X7MO2l5Srjj3JZVpoGX4uqo8XEYlcrK8sBihUtdLsvZR072IRianYBwE100hbnt5eHR4SkXiKfRCk6qcD0LdJN6gRkXiKfRCkG9sBGOheE3ElIiLRiH0Q1DQFQTDco2sJRCSeYh8Edc1BEOT7FQQiEk+xD4KGlmkAFAd0gxoRiafYB0EqXc0gGRjS1cUiEk+xDwKAPqunIqvTR0UknhQEwGCygcpcT9RliIhEQkEADFc0UV3YEnUZIiKRUBAA+XQTtcW+qMsQEYmEggAoZppp8D7cPepSREQmnIIAoLqFWhthYHAg6kpERCacggBI1LYC0Ne9PuJKREQmnoIAqKgPgmBgi4JAROJHQQBk6oOri4d7dBN7EYkfBQFQ0xgMRZ3t03hDIhI/CgKgriUYeK44oCAQkfhREAB1ja2U3PBBjTckIvGjIAAsmaLPakmMaLwhEYkfBUGoP1FPxYiGmRCR+FEQhAaTDWTyCgIRiR8FQWiksonqQk/UZYiITLiyBYGZfd3MNpjZo7tY/1Yze8TM/mRm95nZMeWqZW/k0s3UlTTwnIjETzlbBDcAZ+5m/XPAq939KODfgK+UsZY9KmWaaPA+SsVSlGWIiEy4sgWBu98L7PI0HHe/z923HpT/HdBZrlr2hlW3UGlF+vvUTyAi8TJZ+gguA27b1Uozu8LMlpnZso0by3PRV7KuDYD+zevK8v4iIpNV5EFgZqcSBMH7d7WNu3/F3Re5+6K2tray1FFRH7yvBp4TkbhJRfnhZnY08DXgLHeP9LLeqoZg4LmRXg08JyLxElmLwMwOAn4AvN3dn4yqjq1qm4KB53IaeE5EYqZsLQIzuxFYDLSaWRfwIaACwN2/BPwL0AJ80cwACu6+qFz17El9SxAEpcFNUZUgIhKJsgWBuy/Zw/p3Au8s1+fvq5raRnKewgc13pCIxEvkncWThSUS9Fg9qWG1CEQkXhQEo2xOTaN6eE3UZYiITCgFwSh9VZ205BQEIhIvCoJRsnWzmVbaiOdHoi5FRGTCKAhGsZa5JMzZvObpqEsREZkwCoJRMtPnA9DzwoqIKxERmTh7FQRmVmNmiXB+gZmda2YV5S1t4jXNORqAkRcejrgSEZGJs7ctgnuBjJl1AD8D3k4wzPSUMntGO895O6kNj0RdiojIhNnbIDB3HwLeCHzR3S8EjixfWdFIJRM8n15AS58ODYlIfOx1EJjZScBbgVvDZcnylBStLc3H0FrcgG9ZGXUpIiITYm+D4D3AtcAP3f0xM5sH3FW2qqJ0yGsA2PzQrXvYUERkatirIHD3e9z9XHf/eNhpvMndry5zbZE46ujjea40ndyjP466FBGRCbG3Zw1918zqzawGeBRYbmbvK29p0ZjXVsvdFa9ievf90Lc26nJERMpubw8NHeHufcD5BLeUnEtw5tCUY2YMH34hCUoM/2Fp1OWIiJTd3gZBRXjdwPnALe6eB7xsVUXs1SefxB9LhzCy7NvgU/ZriogAex8EXwZWAjXAvWY2G+grV1FRO2JGPb+qeS1NA0/D6gejLkdEpKz2trP4OnfvcPezPbAKOLXMtUXGzKh/+VsY8Ay9914fdTkiImW1t53FDWb2aTNbFk7/RdA6mLLOO/FQbvFXUf3ULTCku5aJyNS1t4eGvg70AxeFUx/wjXIVNRk01VSybsHbqPAcI7/9atTliIiUzd4GwcHu/iF3fzacPgLMK2dhk8Gfn3YqdxYXwu++CNmBqMsRESmLvQ2CYTN75dYnZnYKMFyekiaPI2c2cGfbxWTyPRR+r1aBiExNexsEVwJfMLOVZrYS+DzwV2WrahI566xzuLd4FPlfXQe5wajLEREZd3t71tDD7n4McDRwtLsvBE4ra2WTxCsPaeWO1kuoym0m/5vPR12OiMi426c7lLl7X3iFMcDflaGeScfMOOvs87m9+HL815+DgY1RlyQiMq7251aVttuVZl83sw1m9ugu1puZXWdmT5vZI2Z23H7UUlanHNLCL2b+FYniMNlffizqckRExtX+BMGexl64AThzN+vPAuaH0xXApL1yy8y45NzXsrR4Kqk/fgO6n4m6JBGRcbPbIDCzfjPrG2PqB2bu7rXufi+wuyuxzgO+GV6p/Dug0cxm7PM3mCAv62jgqcP/hpFSiqHbPxx1OSIi42a3QeDude5eP8ZU5+6p/fzsDuCFUc+7wmWT1l+dfTLf8HOCq427NAaRiEwN+3NoaMKY2RVbh7fYuDG6ztqZjVUUTvwbNno9Az/5oEYmFZEpIcogWA3MGvW8M1z2Iu7+FXdf5O6L2traJqS4Xbn09KP5WuIiatf9Dn/y9khrEREZD1EGwS3AO8Kzh14B9Lr7pL8lWH2mgs7XXMmzpXYGb/0nKBaiLklEZL+ULQjM7Ebgt8ChZtZlZpeZ2ZVmdmW4yU+BZ4Gnga8Cf12uWsbbm19xMP9TfTG1fU9T/ON3oi5HRGS/mB9gx7kXLVrky5Yti7oM7nh0LW03ncNhVX1U//3DUFkddUkiIrtkZg+6+6Kx1h0QncWT0WuPbOfm1iupzm4g++v/jrocEZGXTEHwEpkZb3zDhdxefDn2689A/7qoSxIReUkUBPvh2FmN3H/Ie6CYY1AXmYnIAUpBsJ8uff1pfNPPouqxpbDmoajLERHZZwqC/TSruZr+l7+XzV7HwC3X6CIzETngKAjGwWVnHMOXE2+mdt39+PIfRV2OiMg+URCMg/pMBXPOuJIVpVkM//QfoZCNuiQRkb2mIBgnbzpxLt+ovZzqwS4K930x6nJERPaagmCcpJIJzjpvCT8vHkfpnk/CwIaoSxIR2SsKgnG0eEEbP+t4F1YcIfvzf4u6HBGRvaIgGEdmxmXnn8E3C6+l4uFvw7o/RV2SiMgeKQjG2WHt9XQd/W56vJrhH+t0UhGZ/BQEZXDVWcfzRb+IqtX3wRM/jbocEZHdUhCUwbS6DM2L/4onSx0M33otFHJRlyQisksKgjK59FXzuT59KVX9qyjd/+WoyxER2SUFQZlkKpK8+uwl3FU8hsJdH4fBTVGXJCIyJgVBGZ17zEy+13IlicIg+Ts/GnU5IiJjUhCUUSJhXHL+mXyrcAbJP9wA65dHXZKIyIsoCMrs5XOaeWz+lfR5FdmffkCnk4rIpKMgmADvPudEPl/6C9Kr7oGnfhZ1OSIiO1AQTIDZLTUkT7icZ0ozyN56LRTzUZckIrKNgmCC/PVrDuezyYtJ9z6DP/C1qMsREdlGQTBBGqoqOP70N3Fv8SgKv/xPGNocdUkiIoCCYEK99aQ53FB7OYlcP8W7PxZ1OSIigIJgQlUkE7zl9Wfy3cJp2ANfg41PRF2SiEh5g8DMzjSzJ8zsaTP7wBjrDzKzu8zsj2b2iJmdXc56JoPTD5/GrzsvZ9DT5G/V6KQiEr2yBYGZJYEvAGcBRwBLzOyInTb7J+Amd18IvBmY8vd4NDOuPvckPp5/ExUr74aHvhN1SSISc+VsEZwAPO3uz7p7DlgKnLfTNg7Uh/MNwJoy1jNpHDmzgdwxF3N/6XCKt10LfbH42iIySZUzCDqAF0Y97wqXjfZh4G1m1gX8FHj3WG9kZleY2TIzW7Zx48Zy1Drh3nfWEfxb4ioKuSz+4/foEJGIRCbqzuIlwA3u3gmcDXzLzF5Uk7t/xd0Xufuitra2CS+yHNrq0lx8zml8In8h9tQd8Kf/i7okEYmpcgbBamDWqOed4bLRLgNuAnD33wIZoLWMNU0qFxzfyRNz3sJDvoDST6+BvrVRlyQiMVTOIHgAmG9mc82skqAz+JadtnkeOB3AzA4nCIKpcexnL5gZH33jsVxbupJ8dgj/0V9DqRR1WSISM2ULAncvAO8C7gBWEJwd9JiZ/auZnRtu9vfA5Wb2MHAjcIl7vA6Wz26p4Q1nLOYjubdhz/wS7r8+6pJEJGbsQPt3d9GiRb5s2bKoyxhXxZJzwfW/4eqNH2Zx8mHs8l9C+1FRlyUiU4iZPejui8ZaF3VnsQDJhPGpi47l2sLl9FKLf/+dkB+OuiwRiQkFwSRxcFstl7325bx7+Aps4+Pw83+JuiQRiQkFwSRy6SvnMjTr1XyL18HvvwJP3hF1SSISAwqCSSSZMD55wdF8ovhmXqiYh9/81zCwIeqyRGSKUxBMMvPaannvnx/FXw5cSXGkH/7vEijkoi5LRKYwBcEkdMnJc2g/+FiuyV8Oq34Dt75XQ1CISNkoCCahRMK4bslC7q85nRuSF8Ifvw13fTTqskRkikpFXYCMrbmmki+97Xgu+NIwB9X3c9q9n4RUGv7sfVGXJiJTjFoEk9hRnQ385xuP4Z2b38aDDa+FX/473Pf5qMsSkSlGLYJJ7o3HdbKqe4iL7nw7P5lZ5PCf/SN4EU6+GsyiLk9EpgAFwQHgPa+Zz8aBLK+//2Jubnde9vN/gQ2PwzmfgYpM1OWJyAFOQXAAMDM+ev7LqE2neP29l3J952zOfPgbsOlJeNO3oX5G1CWKyAFMfQQHCDPj2rMO4+/OOIwru87gS9M/jG9YAV89FboejLo8ETmAKQgOIGbGu0+fz4defwQfW7WADzZ/mlKiAr5xFjz0XV1rICIviYLgAPSXp8zlUxcew/8+X8ebSv/BSPvxcPNVsPQt0NsVdXkicoBREBygLji+k29eeiJPDqQ5efXVLH/Z++CZu+ALJ8L9X4ZSMeoSReQAoSA4gL1yfiu3vOsUZrXVc/ayhfzrQV8n33EC3HYNfO10eOJ2HS4SkT1SEBzgZrfU8P0rT+K9r1nA/zwOf7b6b3johE/hgxvhxjfB9SfDIzdBsRB1qSIySSkIpoBUMsHfvmY+P7jqZOqqKjj/3plcUPFFnjnlv4IWwQ8uh/9eCL//KuSGoi5XRCYZBcEUcsysRn569av4xF8czeq+AqffOYPLqj9H15lfh9p2+Ok/wGePgns/CUOboy5XRCYJ3bx+ihrJF7nhvpV88a6n6c8W+IuFHbz/yC20PfRFeOpnkKyE+a+FI86DBWdCpj7qkkWkjHZ383oFwRTXM5Tj+ruf4Rv3rQSH846dyVVHZpm36gew/GboXxuEwsGnB6Fw6FlQ1Rhx1SIy3hQEwuqeYb509zN878EuhvNFXjW/lbeeMIvTa1dR8cSPYfmPoK8LEhUwbzHMPyN4bF2gwe1EpgAFgWzTM5TjO/c/z//ct5IN/Vkaqys4+6gZnHv0DE6oXElixY9gxY9hy3PBC+pmwrxXw6wToXMRtB0OSQ1RJXKgiSwIzOxM4HNAEviau39sjG0uAj4MOPCwu79ld++pIBgfhWKJXz29iR/+YTU/X76e4XyR6fVpzjl6Jmcf1c6xtb0kV94TXKT23L0wHHYuV1TDzIXQcRx0LArCob5DrQaRSS6SIDCzJPAkcAbQBTwALHH35aO2mQ/cBJzm7lvMbJq7b9jd+yoIxt9gtsCdj2/glofWcM+TG8gXneaaSl69oI1XL2jjlINbaMuvhtUPQtey4HHdI1DMBW9QOz0IhY7jYPrLYNrh0DALEjopTWSy2F0QlLONfwLwtLs/GxaxFDgPWD5qm8uBL7j7FoA9hYCUR006xbnHzOTcY2bSO5znnic38ssV67nnyY388I+rATisvY5XzDuSE+e+ihP+rJmWDLD+0WDk09VhODxx6/Y3rayFtsOCqXkONM0NpzlQ3awWhMgkUs4WwQXAme7+zvD524ET3f1do7a5maDVcArB4aMPu/vtY7zXFcAVAAcddNDxq1atKkvNsqNiyXl0dS+/eWYTv3l6Ew+u2sJIvgTAvNYaju5s4KjORo7pbODImQ1UlQZgw4pR03LY9BQMrNvxjdP1QSA0zYHmMBy2hkTDLPVBiJRBVIeG9iYIfgLkgYuATuBe4Ch379nV++rQUHRyhRJ/Wt3L/c9188fne/hTVy/r+kYASBgsmF7HUR0NHD6jnkPb6zisvY6W2nRwNXPPKtj8HGxZGXREb1kZPO9Ztf0QE4AloXHW9mCo74CaVmg8CBo6g+fp2ii+vsgBLapDQ6uBWaOed4bLRusC7nf3PPCcmT0JzCfoT5BJpjKV4PjZTRw/u2nbsvV9I/ypq5dHunp4ZHUvv3x8A//34PahsNvq0hzWXsch02qZ13YkB7edwJzDa2ivz5BIWDBKav/aHUNi6/zym2F4y4sLSddDXXs4zYD6mUFI1IbLaqdD7TRIpcu+T0SmgnIGwQPAfDObSxAAbwZ2PiPoZmAJ8A0zawUWAM+WsSYZZ9PrM0w/IsNrjpgOgLuzaSDHE+v6eXxdH4+Hj//7wAsM5bYPjZ2pSDCnpYZ5bTXMbqmhvX4WBzUfSmdHFTMbq6hJhz/NQi44tNTbBb2rg2sd+tcF4dG/Dlb9FvrXQGmMQfWqmoJwqJ0WBsS0MCSm7zifrodEUv0WEltlCwJ3L5jZu4A7CI7/f93dHzOzfwWWufst4brXmtlyoAi8z927y1WTlJ+Z0VaXpq0uzSvnt25b7u6s6xvhuY2DPLtpkOfCacXafn722HoKpR0PUdZnUsxsrKKjMQiGpppWDm6bzfSZGdrrM0yvz1BVmQw2LhVhYEMQDgMbguAY2AAD64OwGFgPz/8ueCyMjF14zbTgkFRtO9RN3/GxfgbUd6qTW6YsXVAmkSuVnO7BHKu6B1ndM8yanhHW9Ayzpmc4fD5Mf7bwolsrNFRVMKMhCIW2ujSttWlaayuDIKpN0xoua6yqCA5DuUO2f3tIDKwP5gc3QP/6oGXRvz4IlOExBuWrqNneud0cngW19VGd3DLJRdVHILJXEontrYgxf6UEg+i9sHmI9X1Z1vWNsL5vhHW9I6wLH59c38+mgSz54ov/sEkljJbayjAo0mFotNBaOyOYb03T0VhFS20ltekUZhYekgrDom8N9K2GLauCPoxNT8FTP4didtSXSAVh0DzvxSHRNAcqq8uy70TGg4JADgiZiiTzp9cxf3rdLrdxd3qH82wayLKxP8fGgSyb+rNsGsiGy7JsGsjtNjQqUwnatoVFmra6SlpqDqW55ijaOzN0vKyKGY0ZWqsrSAysg83PjurgDh9XL4OR3h3fuLY9CInWQ4Lxm1oPhdb5wdlQieR47y6RfaJDQxJLo0NjQ3+WNT0jdA9k6R7MsbF/a2gE0+bBHDt1YVCZTDC9Ic2MhipmNmSY2VjFjMZgfkZDFR3pYeqHu7AdQuLZoDUxtGn7G6Uy0HJIEApbw6F1QfBYUTWxO0WmNA06J7IfSqUgNNb0DrN6yzBre0dY0zvM2p4R1vYGfRrr+0Ze1OFdVZFkRmOGmQ1VzGquZnZLNXNaqplbneMg76Kq9xnY9CRsfDJ47FkFXgpfbcGhpsZZwbUTDZ0vnjINE78z5IClIBAps2LJ2TSQZU1PGBTh49reYVb3jPB89yBbhvI7vKa1tpK5rTUc3FbL7JYa5jQkOTi5jpmFF6jpexbb/Ex42uwLQT/FzqfIVtaFoTAqKOo7ty+r79C1FLKNOotFyiyZsOCaivoMC3exTd9Inue7h1jVPcSqzYOs2jTEc5sG+fny9XQPjrq6mmpq08fS2XQSs5qrmXVwNQc1VTKvaojZqc1M826qhtaEIRFOax7a8ZDTVrXTR7UoZgUX39VOg5q2YKpqDK6jqKzVIIExphaByCQwkC3wwuahYNoyPGp+iBc2DzOcL+6w/dZTZ9sbMkyrS9Nen6Gj1phd2cMM30R9bj112XWkBnYKjPzQLiowSNcFoZCuC25dmq4PH+tGzdfvNL9124ZgPlVZ/p0lL4laBCKTXG06xeEz6jl8xovvHe0eXGexNSS2XmOxpmeY9X1ZVqztY2N/dqcO7WkkE9OZ2XgiMxqqaGtO0zarko5MlvbUANOS/bTSQ70NUetDZIoDWG4Asn3BGU/Z/qCFsfnZYD7bt+uL8UZLZXYfIOnaYJvKWqisCafR8zXBPS8qq4PrNhQsE0JBIDLJmdm2ayAWHtQ05jaFYokN/VnW9gbh0Decp2vLMM9vHmJd3wgr1vRxb3+W/uzWfgYDmsIpuGC6oaqCpupK6qsqqM+k6GytpqGqgsbqChqrKmjKOM3JHI3JYRoTw9QyRLo4SGJrUGT7YCR8zPZvn+/euONy9uEoRCIVBEOyInisqAqCpKIqnK+CikywboflmZ0e08H8tseqIGSSlcF7p7Zuk4ZkOnZDjigIRKaAVDLBzHA4jt3JFopsHszRPZCjezDH5sEs3QM5eofz9Azl6RnO0zOUY8tQjhVr++kdzo15vcV2Rl26mZbaduoyFdSmU9RlUtRmUtTVpahtS1GbrqA2k6I+k6K2MkldRYn6ZI7K0jDVjNCUylNZGsJyQ5AbhPxgMGLttsfhYITa/DAUhiE/Ehziyg/DUHf4fKd1+xI2u/heQUhsDYp08Lh1WUVV2HKp2XG7bdukw20y28PKkmEIVQavTYTvu3NwJSuDq9STlcE2yYqyh5KCQCRG0qkkMxqqmNGwd9couDtDuSK9w/ltYdE7nAsf89vWdQ/mGBjJM5At8PzmIQayBfpHCgxkCxR3vghjDGaQSSWpqmykqqKFqsokVRXBVHKnvipolVRVJklVGomEUVWRpCadojadoqoyibvTVF1JZdLIJIpUWY4qy5OxPGnLU+l50uSpJEeymMUKI1DKQyEbHPbKjwSBU8yHjztP4bZbQyk/FJzNtW378HHre+aHRp0OvJ8SqSAUTn43nPaP4/OeoygIRGSXzIyadIqadGqPrY2xuDsj+RL92TwDYTD0jxToH8lTKDmD2QLdgzlGckWG8+GUKzGSLzKUKzCcL5KyxLZhRIZzRQolp1RyhvPFF127sfffCyqSFVQm01Qk66hMJaiuTJFOJahMJahMJkgljWTCSKeCQEolDXcouVOZTtDSXEkiYWRSSWrSSRJmpBJGKpmgImkkzUgni1Rbngw5MhRIJwpUWolKz5K2IhXk8PwI1ZYlWcySLGVJeQErFYJAKeagWNgeMJ27GoRl/ygIRKRszCz4674yybRdjw7ykrg72UKJwWyBoVyRkjt9wwVyxRLZQpFsocRILnjMForkCqVwvkQ2XyRfcnKFEvliiWy+xGCuQK5QIlcskSuUKBSDsOkdzjOcK25r2SQSRjZfonsw6KDPFfb3r/4EUBVOgXQqEUwVSYxgvKxMRZK3VB3EOxfs58eNQUEgIgcks+Afx0xFkpYI6yiGrZNiySmWnEKxRL7kFItOrljcFj65cNo2XyySzZdImNGfLVAoliiUnGy+SDYMp2yhhLtv+4zW2vJcIKggEBHZD8mEUZs+sP8p1aWEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCIiMScgkBEJOYOuBvTmNlGYNVLfHkrMMZtnGJL+2NH2h870v7Ybirsi9nu3jbWigMuCPaHmS3b1R164kj7Y0faHzvS/thuqu8LHRoSEYk5BYGISMzFLQi+EnUBk4z2x460P3ak/bHdlN4XseojEBGRF4tbi0BERHaiIBARibnYBIGZnWlmT5jZ02b2gajrKTczm2Vmd5nZcjN7zMz+NlzebGY/N7OnwsemcLmZ2XXh/nnEzI6L9huUh5klzeyPZvaT8PlcM7s//N7/a2aV4fJ0+PzpcP2cSAsvAzNrNLPvmdnjZrbCzE6K8+/DzN4b/r/yqJndaGaZuPw+YhEEZpYEvgCcBRwBLDGzI6KtquwKwN+7+xHAK4C/Cb/zB4A73X0+cGf4HIJ9Mz+crgCun/iSJ8TfAitGPf848Bl3PwTYAlwWLr8M2BIu/0y43VTzOeB2dz8MOIZgv8Ty92FmHcDVwCJ3fxmQBN5MXH4f7j7lJ+Ak4I5Rz68Fro26rgneBz8CzgCeAGaEy2YAT4TzXwaWjNp+23ZTZQI6Cf5xOw34CWAEV4umdv6dAHcAJ4XzqXA7i/o7jOO+aACe2/k7xfX3AXQALwDN4X/vnwB/HpffRyxaBGz/j7xVV7gsFsJm60LgfmC6u68NV60DpofzcdhHnwWuAUrh8xagx90L4fPR33nb/gjX94bbTxVzgY3AN8JDZV8zsxpi+vtw99XAp4DngbUE/70fJCa/j7gEQWyZWS3wfeA97t43ep0Hf87E4vxhMzsH2ODuD0ZdyySRAo4Drnf3hcAg2w8DAbH7fTQB5xEE5EygBjgz0qImUFyCYDUwa9TzznDZlGZmFQQh8B13/0G4eL2ZzQjXzwA2hMun+j46BTjXzFYCSwkOD30OaDSzVLjN6O+8bX+E6xuA7oksuMy6gC53vz98/j2CYIjr7+M1wHPuvtHd88APCH4zsfh9xCUIHgDmh2cAVBJ0At0ScU1lZWYG/D9ghbt/etSqW4CLw/mLCfoOti5/R3h2yCuA3lGHCA547n6tu3e6+xyC//6/dPe3AncBF4Sb7bw/tu6nC8Ltp8xfx+6+DnjBzA4NF50OLCemvw+CQ0KvMLPq8P+drfsjHr+PqDspJmoCzgaeBJ4B/jHqeibg+76SoFn/CPBQOJ1NcBzzTuAp4BdAc7i9EZxZ9QzwJ4KzJyL/HmXaN4uBn4Tz84DfA08D/wekw+WZ8PnT4fp5Udddhv1wLLAs/I3cDDTF+fcBfAR4HHgU+BaQjsvvQ0NMiIjEXFwODYmIyC4oCEREYk5BICIScwoCEZGYUxCIiMScgkBkJ2ZWNLOHRk3jNlqtmc0xs0fH6/1ExkNqz5uIxM6wux8bdREiE0UtApG9ZGYrzewTZvYnM/u9mR0SLp9jZr8Mx+m/08wOCpdPN7MfmtnD4XRy+FZJM/tqOPb9z8ysKrIvJYKCQGQsVTsdGnrTqHW97n4U8HmC0UwB/hv4H3c/GvgOcF24/DrgHnc/hmAcn8fC5fOBL7j7kUAP8Bdl/TYie6Ari0V2YmYD7l47xvKVwGnu/mw4oN86d28xs00EY/Pnw+Vr3b3VzDYCne6eHfUec4Cfe3DjF8zs/UCFu//7BHw1kTGpRSCyb3wX8/siO2q+iPrqJGIKApF986ZRj78N5+8jGNEU4K3Ar8L5O4GrYNu9khsmqkiRfaG/RERerMrMHhr1/HZ333oKaZOZPULwV/2ScNm7Ce709T6Cu379Zbj8b4GvmNllBH/5X0Vw9yuRSUV9BCJ7KewjWOTum6KuRWQ86dCQiEjMqUUgIhJzahGIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjM/X+TOJZDE+qK2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history = model.get_history()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.get_history()\n",
    "\n",
    "plt.plot(history.history['accuracy'] )\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
